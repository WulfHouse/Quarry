---
title: "Tooling: Quarry Build System"
section: 8
order: 8
---

# Tooling: Quarry Build System

================================================================================

Pyrite's official build system and package manager is Quarry. The design 
philosophy mirrors Cargo (Rust's beloved build tool): provide one obvious 
workflow that handles everything, eliminate configuration complexity, and make 
the right thing the easy thing.

Developer surveys consistently show that great tooling is essential for language 
adoption. Quarry is designed as a first-class component of Pyrite, not an 
afterthought.

8.1 Core Quarry Workflow
--------------------------------------------------------------------------------

Single Command Philosophy
~~~~~~~~~~~~~~~~~~~~~~~~~

Quarry provides one intuitive command for each common task:

    quarry new myproject          # Create new project
    quarry build                  # Compile (debug mode)
    quarry build --release        # Compile (optimized)
    quarry run                    # Build and execute
    quarry test                   # Run all tests
    quarry bench                  # Run benchmarks
    quarry doc                    # Generate documentation
    quarry fmt                    # Format all code
    quarry lint                   # Run linter
    quarry clean                  # Remove build artifacts
    quarry publish                # Publish to package registry

No makefiles, no build scripts, no configuration hell. It just works.

Script Mode: Single-File Workflow
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For rapid prototyping, learning, and simple scripts, Pyrite supports a 
zero-configuration single-file workflow that feels like Python but compiles to 
native code:

    pyrite run hello.pyrite       # Compile and execute single file
    pyrite build hello.pyrite     # Compile to executable
    pyrite hello.pyrite           # Shorthand for 'run'

No project structure required. No Quarry.toml needed. Just write code and run it.

Example workflow:

    # Create a simple script
    $ cat > hello.pyrite
    fn main():
        print("Hello, Pyrite!")
    ^D
    
    # Run it immediately
    $ pyrite run hello.pyrite
    Hello, Pyrite!
    
    # Compile to standalone executable
    $ pyrite build hello.pyrite
    Compiling hello.pyrite â†’ hello (or hello.exe on Windows)
    
    $ ./hello
    Hello, Pyrite!

Shebang Support
~~~~~~~~~~~~~~~

On Unix-like systems, Pyrite scripts can use shebang lines for direct execution:

    #!/usr/bin/env pyrite
    
    fn main():
        print("Executable Pyrite script!")

Make the file executable and run:

    $ chmod +x script.pyrite
    $ ./script.pyrite
    Executable Pyrite script!

Script Mode Implementation
~~~~~~~~~~~~~~~~~~~~~~~~~~

Script mode is implemented as intelligent caching:

  1. **First run:** Compiles to ~/.cache/pyrite/scripts/<hash>/binary
  2. **Subsequent runs:** Reuses cached binary if source unchanged
  3. **Automatic recompilation:** Detects source changes and recompiles
  4. **Full ownership checking:** Script mode uses the same compiler with all 
     safety guarantees
  5. **Zero runtime overhead:** Cached binaries are native executables, not 
     interpreted

This means script mode has the convenience of Python's `python script.py` with 
the performance of compiled native code.

Cache management:

    pyrite cache clean            # Remove all cached scripts
    pyrite cache list             # Show cached scripts
    pyrite cache clear hello.pyrite  # Remove specific script cache

Why Script Mode Matters
~~~~~~~~~~~~~~~~~~~~~~~~

Script mode eliminates the biggest friction point for Python developers trying 
Pyrite:

  â€¢ **Instant gratification:** Write code, run code, see results
  â€¢ **No ceremony:** No project structure until you need it
  â€¢ **Natural progression:** Start with scripts, graduate to projects
  â€¢ **Learning-friendly:** Beginners can experiment immediately
  â€¢ **Still fast:** Caching means second run is instant

This addresses the "first 60 seconds" problem: a Python developer's first 
experience with Pyrite should feel familiar, not foreign.

Comparison:

    # Python
    $ python script.py           # Interpreted, ~100ms startup
    
    # Pyrite script mode
    $ pyrite run script.pyrite   # Compiled + cached, ~1ms after first run
    
    # Pyrite project mode
    $ cd project && quarry run   # Full build system

All three workflows coexist. Use the right tool for the job.

Migration Path
~~~~~~~~~~~~~~

When a script grows complex enough to need dependencies, migrate to project mode:

    $ quarry init              # Convert current directory to Quarry project
    $ mv script.pyrite src/main.pyrite
    $ quarry add dependency-name
    $ quarry build

Quarry detects single-file scripts and can auto-generate appropriate Quarry.toml.

Project Structure
~~~~~~~~~~~~~~~~~

quarry new creates a standard layout:

    myproject/
    â”œâ”€â”€ Quarry.toml        # Project manifest
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ main.pyrite    # Entry point
    â”œâ”€â”€ tests/
    â”‚   â””â”€â”€ test_main.pyrite
    â””â”€â”€ docs/
        â””â”€â”€ README.md

Quarry.toml example:

    [package]
    name = "myproject"
    version = "0.1.0"
    authors = ["Your Name <you@example.com>"]
    edition = "2025"
    
    [dependencies]
    json = "1.2"
    http-client = "3.0"
    
    [dev-dependencies]
    test-utils = "0.5"

8.2 Dependency Management
--------------------------------------------------------------------------------

Declarative Dependencies
~~~~~~~~~~~~~~~~~~~~~~~~

Dependencies are declared in Quarry.toml with semantic versioning:

    [dependencies]
    crypto = "2.1"          # Any 2.x version >= 2.1
    parser = "=1.5.3"       # Exact version
    utils = { git = "https://github.com/user/utils.git", branch = "main" }

quarry build automatically:
  â€¢ Downloads dependencies
  â€¢ Resolves version conflicts
  â€¢ Generates Quarry.lock (lockfile for reproducibility)
  â€¢ Caches builds for speed

Reproducible Builds
~~~~~~~~~~~~~~~~~~~

Quarry.lock ensures every developer/CI system builds identical binaries:

    [[package]]
    name = "crypto"
    version = "2.1.4"
    checksum = "a8f39d..."
    
    [[package]]
    name = "parser"
    version = "1.5.3"
    checksum = "b3c82f..."

Lockfile committed to version control guarantees reproducibility across 
environments and time.

8.3 Official Package Registry
--------------------------------------------------------------------------------

Pyrite packages are published to the official Quarry Registry (quarry.dev):

    quarry publish

Publishing requirements:
  â€¢ Semantic versioning
  â€¢ Documentation for public APIs
  â€¢ Passing tests (quarry test must succeed)
  â€¢ License declaration
  â€¢ Security audit for unsafe code (optional but recommended)

Discovery and search:

    quarry search "json parser"
    quarry info json-parser

Registry provides:
  â€¢ API documentation (auto-generated)
  â€¢ Download statistics
  â€¢ Security advisories
  â€¢ Dependency graphs
  â€¢ Version compatibility matrices

8.4 Testing Framework
--------------------------------------------------------------------------------

Built-in Test Support
~~~~~~~~~~~~~~~~~~~~~

Tests are first-class in Pyrite:

    # In src/math.pyrite
    fn add(a: int, b: int) -> int:
        return a + b
    
    @test
    fn test_add():
        assert add(2, 3) == 5
        assert add(-1, 1) == 0
    
    @test
    fn test_add_overflow():
        # Tests can use Result types
        match add(MAX_INT, 1):
            Err(_):
                pass  # Expected overflow in debug mode
            Ok(_):
                fail("Should have overflowed")

Run tests:

    quarry test                    # All tests
    quarry test test_add          # Specific test
    quarry test --verbose         # Detailed output

Benchmark Support
~~~~~~~~~~~~~~~~~

Performance testing built-in:

    @bench
    fn bench_parse_json(b: &mut Bencher):
        let data = load_test_data()
        b.iter(fn():
            parse_json(data)
        )

Run benchmarks:

    quarry bench                   # Run all benchmarks
    quarry bench --save baseline   # Save baseline for comparison

8.5 Code Formatting
--------------------------------------------------------------------------------

Official Formatter
~~~~~~~~~~~~~~~~~~

quarry fmt formats all code according to official style guide:

    quarry fmt                     # Format entire project
    quarry fmt src/parser.pyrite   # Format specific file
    quarry fmt --check             # Check without modifying (for CI)

No configuration options. Zero style debates. One canonical format.

Formatting rules:
  â€¢ 4 spaces for indentation (enforced)
  â€¢ Maximum line length: 100 characters
  â€¢ Consistent spacing around operators
  â€¢ Idiomatic pattern for common constructs

Example transformation:

    # Before
    fn   foo(x:int,y:int)->int:
        return    x+y

    # After quarry fmt
    fn foo(x: int, y: int) -> int:
        return x + y

8.6 Learning Profile Mode
--------------------------------------------------------------------------------

To support Pyrite's goal of being approachable to beginners, Quarry provides a 
"Learning Profile" that packages beginner-friendly defaults into a one-command 
setup:

    quarry new --learning my_project

This creates a project configured for gentle onboarding:

  â€¢ Enables --core-only mode (rejects advanced features)
  â€¢ Sets beginner lint level (quarry lint --level=beginner)
  â€¢ Includes extra IDE hover help
  â€¢ Forbids unsafe blocks by default
  â€¢ Configures progressive learning paths in tooling
  â€¢ Adds commented examples in generated files

The Learning Profile is purely a packaging of existing features - no new semantics, 
just a curated "beginner bundle" that grows with the developer:

Configuration (Quarry.toml):

    [profile.learning]
    core-only = true
    lint-level = "beginner"
    unsafe-forbidden = true
    extra-diagnostics = true
    suggest-alternatives = true

Migration path:

    # After mastering basics, disable learning mode
    quarry config set learning false
    
    # Or migrate incrementally
    quarry config set core-only false  # Enable advanced features
    quarry config set lint-level intermediate

Benefits:
  â€¢ Zero new language complexity (just configuration)
  â€¢ One-command setup for educators and self-learners
  â€¢ Natural graduation path as skills advance
  â€¢ All code remains valid Pyrite (no dialect fragmentation)

Marketing impact: "Pyrite has a beginner mode" is a powerful message for 
Python developers exploring systems programming.

Implementation: Beta Release (after core compiler and lints are stable)

8.7 Interactive REPL (Beta Release)
--------------------------------------------------------------------------------

To deliver on Pyrite's promise of Python-like approachability, the language 
provides an interactive Read-Eval-Print Loop (REPL) with ownership visualization 
and cost transparency built in. This is essential for the "Pythonic" claim - 
Python developers expect instant experimentation.

Command Usage
~~~~~~~~~~~~~

    pyrite repl                      # Launch interactive shell
    pyrite repl --explain            # Enhanced mode with ownership visualization
    pyrite repl --script=setup.py    # Load script before interactive session

Basic REPL Workflow
~~~~~~~~~~~~~~~~~~~

    $ pyrite repl
    
    Pyrite 1.0.0 (2025-12-18)
    Type :help for help, :quit to exit
    
    >>> let x = 5
    let x: int = 5
    
    >>> let data = List[int]([1, 2, 3])
    let data: List[int] = List[int]([1, 2, 3])
    [Heap] [Move] Stack: 24B, Heap: 12B
    
    >>> data.push(4)
    error[P0594]: cannot borrow 'data' as mutable
      = note: 'data' declared with 'let' (immutable)
      = help: Use 'var data' to allow mutation
    
    >>> var mutable_data = List[int]([1, 2, 3])
    var mutable_data: List[int] = List[int]([1, 2, 3])
    
    >>> mutable_data.push(4)
    () â† pushed successfully
    
    >>> mutable_data
    List[int]([1, 2, 3, 4])

Enhanced REPL Commands
~~~~~~~~~~~~~~~~~~~~~~~

The REPL provides special commands for exploration:

    >>> :type data
    Type: List[int]
    Badges: [Heap] [Move] [MayAlloc]
    Stack: 24 bytes, Heap: 16 bytes (capacity for 4 elements)
    Owner: 'data', Not moved, Not borrowed
    
    >>> :ownership data
    Ownership State for 'data'
    ==========================
    Owner: 'data' (line 5)
    Moved: No
    Borrowed: No active borrows
    
    Next operations:
      âœ“ Can read: data.length(), data[0], etc.
      âœ“ Can mutate: data.push(), data.clear(), etc.
      âš ï¸  Passing to function will move (use &data to borrow)
    
    >>> :cost
    Session Cost Analysis
    =====================
    Allocations: 2 (40 bytes)
      â€¢ Line 5: List[int].new() - 24 bytes
      â€¢ Line 8: mutable_data.push(4) - 16 bytes (reallocation)
    
    Copies: 0
    Total memory: 40 bytes
    
    >>> :explain P0234
    [Opens detailed error explanation for P0234]
    
    >>> :clear
    [Clears session, resets state]

Ownership Visualization Mode
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

With --explain flag, REPL shows ownership changes in real-time:

    $ pyrite repl --explain
    
    >>> let data = List[int]([1, 2, 3])
    
    â”Œâ”€â”€â”€â”€â”€â”
    â”‚data â”‚ â† OWNER (owns heap allocation)
    â””â”€â”€â”€â”€â”€â”˜
    
    >>> process(data)
    
    data â”€â”€[MOVED]â”€â”€> process()
    
    >>> data.length()
    
    error: Cannot use moved value
    
    â”Œâ”€â”€â”€â”€â”€â”
    â”‚data â”‚ â† INVALID (moved on line 2)
    â””â”€â”€â”€â”€â”€â”˜
    
    Fix suggestions:
      1. process(&data)  # Borrow instead
      2. data.clone()    # Copy before moving

This real-time visualization makes ownership tangible - learning happens 
immediately, not after compilation.

Function Definitions
~~~~~~~~~~~~~~~~~~~~

Define functions interactively:

    >>> fn add(a: int, b: int) -> int:
    ...     return a + b
    ... 
    fn add(a: int, b: int) -> int
    
    >>> add(5, 3)
    8
    
    >>> fn process[N: int](arr: [int; N]) -> int:
    ...     var sum = 0
    ...     for x in arr:
    ...         sum += x
    ...     return sum
    ... 
    fn process[N: int](arr: [int; N]) -> int
    
    >>> process[3]([1, 2, 3])
    6

Multi-Line Editing
~~~~~~~~~~~~~~~~~~

REPL supports multi-line constructs with intelligent continuation:

    >>> for i in 0..5:
    ...     print(i)
    ... 
    0
    1
    2
    3
    4

Session Management
~~~~~~~~~~~~~~~~~~

    :save session.pyr               # Save session to file
    :load session.pyr               # Load previous session
    :history                        # Show command history
    :clear                          # Reset session state

Import Support
~~~~~~~~~~~~~~

Import modules during interactive session:

    >>> import math
    >>> math.sqrt(16.0)
    4.0
    
    >>> import json
    >>> json.parse('{"key": "value"}')
    Ok(Object({"key": "value"}))

Performance Mode
~~~~~~~~~~~~~~~~

For performance-critical experimentation:

    >>> :perf start                 # Begin performance tracking
    >>> expensive_computation()
    >>> :perf stop
    
    Performance Profile
    ===================
    Duration: 234ms
    Allocations: 1,247 (1.2 MB)
    Peak memory: 2.4 MB

Why REPL Is Essential
~~~~~~~~~~~~~~~~~~~~~

The absence of a REPL would be a **critical gap** for Pyrite's positioning:

**Python developers expect it:**
  â€¢ REPL is 50% of Python's "instant gratification" appeal
  â€¢ Exploration-driven learning is how beginners understand concepts
  â€¢ "Just try it" is more powerful than "read about it"
  â€¢ Without REPL, "Pythonic systems language" claim feels hollow

**Learning acceleration:**
  â€¢ Try ownership patterns instantly without compilation
  â€¢ See borrow checker feedback in real-time
  â€¢ Experiment with types, memory layout, costs interactively
  â€¢ Reduce friction from "change code â†’ compile â†’ run" to "just try"

**Competitive necessity:**
  â€¢ Rust: Has REPL (evcxr) but third-party, not built-in
  â€¢ Python: REPL is flagship feature
  â€¢ JavaScript: Node.js REPL is critical to adoption
  â€¢ Swift: Has REPL (swift repl) for iOS development
  â€¢ Mojo: Has REPL (mojo repl) with instant feedback

**Teaching impact:**
  â€¢ Instructors can demonstrate concepts live
  â€¢ Students experiment during lectures
  â€¢ Ownership becomes interactive ("try moving it, see what happens")
  â€¢ Reduces "scary compiler" perception

Implementation Approach
~~~~~~~~~~~~~~~~~~~~~~~

REPL compiles each expression/statement incrementally:

  â€¢ JIT compilation for speed (LLVM OrcJIT or similar)
  â€¢ Ownership tracking persists across statements
  â€¢ Type inference works across session
  â€¢ Memory is actual (not simulated)-real allocations, real costs

Safety in REPL:
  â€¢ Same safety guarantees as compiled code
  â€¢ Unsafe blocks still require unsafe marker
  â€¢ Ownership rules enforced (prevents use-after-free even in REPL)

Integration with Teaching:
  â€¢ quarry learn can open REPL for specific exercises
  â€¢ Compiler errors link to REPL examples: "Try this in REPL"
  â€¢ Documentation examples include REPL transcripts

Example Teaching Session:

    $ pyrite repl --explain
    
    Pyrite Interactive Shell (Learning Mode)
    ========================================
    
    Try this exercise: Create a list, move it, observe the error
    
    >>> let data = List[int]([1, 2, 3])
    
    âœ“ Created owner 'data'
    
    >>> process(data)
    
    âš ï¸  'data' moved to 'process'
    
    >>> data.length()
    
    âœ— Error: 'data' was moved on line 2
    
    What happened?
      â€¢ Line 1: 'data' owned the list
      â€¢ Line 2: Ownership transferred to 'process()'
      â€¢ Line 3: 'data' no longer valid
    
    Fix: Use &data to borrow instead
    
    >>> # Try again...

This transforms abstract concepts into interactive, visual understanding. The 
REPL is not just a nice-to-have - it's **essential for Pyrite's identity** as the 
"Pythonic systems language."

Implementation: Beta Release (high priority, high impact)
Complexity: Moderate (JIT compilation, incremental state management)
Impact: Critical (without REPL, Python developers feel the gap immediately)

8.8 Automatic Code Fixes
--------------------------------------------------------------------------------

quarry fix - Apply Compiler Suggestions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pyrite's compiler doesn't just identify problems - it suggests concrete fixes. The 
quarry fix command automatically applies safe, mechanical transformations that 
the compiler recommends.

Usage:

    quarry fix                     # Apply all safe fixes in project
    quarry fix src/main.pyrite     # Fix specific file
    quarry fix --preview           # Show fixes without applying
    quarry fix --interactive       # Prompt before each fix

Interactive Ownership Error Resolution
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When quarry fix encounters ownership/borrowing errors, it presents numbered, 
selectable fixes that teach the concepts while solving the problem:

Example compilation error:

    error[P0234]: cannot use moved value 'data'
      ----> main.py:15:10
       |
    12 |     let data = List[int]([1, 2, 3])
       |         -------- value allocated here
    13 |     process(data)
       |             -------- value moved here (ownership transferred to 'process')
    15 |     print(data.length())
       |          ^^^^ cannot use 'data' after it was moved
       |
       = help: Run 'quarry fix --interactive' to choose a solution

Running quarry fix --interactive presents:

    Found ownership error at main.py:15:10
    
    'data' was moved on line 13 and cannot be used again.
    
    Select a fix:
      1. Pass a reference to 'process' instead
         - Change: process(data) â†’ process(&data)
         - Effect: 'data' remains usable after the call
         - When to use: Function only needs to read the data
      
      2. Clone the value before moving
         - Change: process(data) â†’ process(data.clone())
         - Effect: 'data' remains usable (original retained)
         - When to use: Function needs ownership but you need the data later
         - Cost: Allocates and copies the entire list
      
      3. Restructure to return ownership
         - Change: data = process(data)
         - Effect: 'process' gives ownership back
         - When to use: Function transforms data and you need result
      
      4. Skip this fix
    
    Choice (1-4): _

This interactive mode:
  â€¢ **Teaches patterns:** Each option explains when to use it
  â€¢ **Shows trade-offs:** Performance implications visible (e.g., "allocates")
  â€¢ **Builds intuition:** Repeated fixes teach ownership patterns organically
  â€¢ **Safe by default:** Only presents compiler-verified transformations

Non-interactive mode (quarry fix) applies the safest/cheapest fix automatically 
(typically option 1: borrow instead of move).

Ownership Error Coverage:
  â€¢ Move-after-use: Offer borrow, clone, or restructure
  â€¢ Borrow conflicts: Suggest scope reduction or explicit drop
  â€¢ Lifetime issues: Add lifetime annotations or restructure
  â€¢ Double move: Clone first move or restructure logic

Types of automatic fixes:

1. **Ownership fixes:**
   
   Before:
       let data = List[int]([1, 2, 3])
       process(data)
       print(data.length())  # ERROR: value moved
   
   After quarry fix:
       let data = List[int]([1, 2, 3])
       process(data.clone())  # Added .clone()
       print(data.length())

2. **Borrowing fixes:**
   
   Before:
       fn process(list: List[int]) -> int:  # Takes ownership
           list.length()
   
   After quarry fix:
       fn process(list: &List[int]) -> int:  # Borrows instead
           list.length()

3. **Performance fixes:**
   
   Before:
       for i in 0..1000:
           let v = List[int].new()  # Allocates in loop
   
   After quarry fix:
       let v = List[int].with_capacity(10)
       for i in 0..1000:
           v.clear()

4. **Type annotations:**
   
   Before:
       let x = parse(input)  # Ambiguous type
   
   After quarry fix:
       let x: Result[Config, Error] = parse(input)

5. **Import cleanup:**
   - Remove unused imports
   - Add missing imports
   - Sort and organize imports

6. **Lifetime annotations (advanced):**
   - Add explicit lifetime annotations where inference fails
   - Only for complex generic code

Why quarry fix is transformative:

  â€¢ **Accelerates learning:** Beginners see the pattern of correct code
  â€¢ **Reduces friction:** Fix 10 borrow errors in seconds, not minutes
  â€¢ **Builds intuition:** Repeated fixes teach ownership patterns
  â€¢ **Safe:** Only applies mechanical, verified transformations
  â€¢ **IDE integration:** Real-time "Quick Fix" in editors

Safety guarantees:
  â€¢ Never changes program semantics incorrectly
  â€¢ Only applies fixes the compiler marks as "safe mechanical change"
  â€¢ Preserves code comments and formatting
  â€¢ Can be undone with version control

This is the natural evolution of Pyrite's teaching compiler: diagnose, explain, 
AND fix. It's what makes Elm, rust-analyzer, and go fmt feel magical.

8.9 Fuzzing and Sanitizers
--------------------------------------------------------------------------------

To make Pyrite a production-ready systems language and achieve widespread developer 
adoption, 
runtime verification tools are essential for catching bugs that static analysis 
misses. These tools cost zero at runtime (only used during testing) but multiply 
reliability dramatically.

quarry fuzz - Coverage-Guided Fuzzing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Automatic test generation that explores edge cases:

    quarry fuzz                         # Fuzz all fuzzable functions
    quarry fuzz parse_packet            # Fuzz specific function
    quarry fuzz --duration=1h           # Run for 1 hour
    quarry fuzz --corpus=./inputs       # Use seed inputs

How it works:
  â€¢ Identifies functions marked @fuzz or with fuzz_ prefix
  â€¢ Generates random inputs based on parameter types
  â€¢ Tracks code coverage and prioritizes unexplored paths
  â€¢ Saves crash-inducing inputs for reproduction

Example fuzzable function:

    @fuzz
    fn parse_packet(data: &[u8]) -> Result[Packet, Error]:
        # Fuzzer generates thousands of random byte arrays
        # Finds inputs that panic, overflow, or violate assertions
        ...

Fuzzing output:

    $ quarry fuzz parse_packet --duration=10m
    
    Fuzzing: parse_packet
    =====================
    
    Progress:
      â€¢ Iterations: 1,247,892
      â€¢ Coverage: 89% of function body
      â€¢ Unique paths: 234
      â€¢ Crashes found: 2
    
    ğŸ”´ CRASH #1: Integer overflow
       Input: [0xff, 0xff, 0xff, 0xff, 0x01]
       Location: src/parser.py:234
       
       thread 'fuzzer' panicked at 'attempt to multiply with overflow'
         length = u32::from_bytes([0xff, 0xff, 0xff, 0xff])  # 4,294,967,295
         total_size = length * FIELD_SIZE  # Overflows!
       
       Fix: Use checked arithmetic:
         let total_size = length.checked_mul(FIELD_SIZE)?
       
       Saved to: fuzz/crashes/crash-1.bin
       Reproduce: quarry test --fuzz-input=fuzz/crashes/crash-1.bin
    
    ğŸ”´ CRASH #2: Slice index out of bounds
       Input: [0x00, 0x05]  # Claims 5 fields, provides 0
       Location: src/parser.py:267
       [Details...]
    
    Summary:
      âœ“ Found 2 bugs that unit tests missed
      âœ“ Corpus saved to fuzz/corpus/ (1,247 interesting inputs)
      âœ“ Add these to regression tests

Integration with CI:

    # Run fuzzing in CI for 5 minutes
    quarry fuzz --ci --duration=5m
    
    # Exit 0 if no crashes, exit 1 if crashes found

Why Fuzzing Matters:
  â€¢ Finds edge cases humans miss (off-by-one, overflow, malformed inputs)
  â€¢ Generates regression tests automatically (save crash inputs)
  â€¢ Industry standard for security-critical code
  â€¢ Minimal setup cost (just mark functions with @fuzz)

Fuzz Testing Best Practices:

    @fuzz
    @cost_budget(cycles=10000, allocs=2)  # Budgets still enforced
    fn parse_header(data: &[u8]) -> Result[Header, Error]:
        # Fuzzer explores all code paths
        # Cost budget prevents infinite loops or excessive allocation
        ...

Implementation: Beta Release (after core test framework is stable)

quarry sanitize - Runtime Error Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Compiler-integrated sanitizers detect undefined behavior and memory errors at 
runtime (debug/test builds only):

    quarry sanitize --asan              # AddressSanitizer
    quarry sanitize --tsan              # ThreadSanitizer  
    quarry sanitize --ubsan             # UndefinedBehaviorSanitizer
    quarry sanitize --msan              # MemorySanitizer
    quarry sanitize --all               # All sanitizers

AddressSanitizer (ASan) - Memory Error Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Detects memory safety violations at runtime:

    quarry sanitize --asan
    quarry test  # Tests run with ASan instrumentation

Catches:
  â€¢ Use-after-free
  â€¢ Heap buffer overflow
  â€¢ Stack buffer overflow
  â€¢ Memory leaks
  â€¢ Use of uninitialized memory

Example output:

    $ quarry sanitize --asan
    $ quarry test
    
    Running tests with AddressSanitizer...
    
    test test_parse_large ... ok
    test test_edge_cases ... FAILED
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    AddressSanitizer: heap-buffer-overflow
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    READ of size 4 at 0x60300000eff4 thread T0
        #0 process_buffer src/processor.py:234
        #1 test_edge_cases tests/test_parser.py:45
    
    0x60300000eff4 is located 4 bytes after 1024-byte region
    allocated by thread T0:
        #0 malloc
        #1 List::with_capacity src/std/collections.py:89
        #2 test_edge_cases tests/test_parser.py:42
    
    SUMMARY: AddressSanitizer: heap-buffer-overflow
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Fix: Buffer accessed beyond allocated size
      Line 234: buffer[1024] when buffer.len() == 1024
      Index 1024 is out of bounds (valid: 0..1023)

ThreadSanitizer (TSan) - Data Race Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Detects concurrent memory access violations:

    quarry sanitize --tsan
    quarry test

Catches:
  â€¢ Data races (unsynchronized concurrent access)
  â€¢ Lock order inversions (potential deadlocks)
  â€¢ Destroyed mutex still in use
  â€¢ Thread leaks

Example output:

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ThreadSanitizer: data race
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Write of size 8 at 0x7b0400001234 by thread T2:
        #0 update_counter src/stats.py:156
        #1 worker_thread src/main.py:89
    
    Previous write of size 8 at 0x7b0400001234 by thread T1:
        #0 update_counter src/stats.py:156
        #1 worker_thread src/main.py:89
    
    Location: counter (global variable)
    
    SUMMARY: ThreadSanitizer: data race
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Fix: Use atomic operations or mutex:
      
      Option 1 (Atomic):
        static COUNTER: AtomicU64 = AtomicU64::new(0)
        COUNTER.fetch_add(1, Ordering::Relaxed)
      
      Option 2 (Mutex):
        static COUNTER: Mutex<u64> = Mutex::new(0)
        *COUNTER.lock() += 1

UndefinedBehaviorSanitizer (UBSan) - UB Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Catches undefined behavior even in safe-looking code:

    quarry sanitize --ubsan
    quarry test

Catches:
  â€¢ Integer overflow (in release mode if checks disabled)
  â€¢ Misaligned pointer access
  â€¢ Invalid enum discriminant values
  â€¢ Shift by negative or >= width
  â€¢ Division by zero

Example:

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    UndefinedBehaviorSanitizer: signed integer overflow
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    src/math.py:456:18: runtime error:
      signed integer overflow: 2147483647 + 1 cannot be represented in type 'i32'
    
    Fix: Use checked arithmetic:
      let result = a.checked_add(b)?

Integration with CI
~~~~~~~~~~~~~~~~~~~

Run all sanitizers in continuous integration:

    # .github/workflows/ci.yml
    - name: Run sanitizers
      run: |
        quarry sanitize --asan && quarry test
        quarry sanitize --tsan && quarry test
        quarry sanitize --ubsan && quarry test

Sanitizer builds are slow (2-5x overhead) but catch bugs that slip through 
static analysis and normal testing.

quarry miri - Interpreter-Based UB Detection (Future)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Long-term goal: Rust's Miri-equivalent for Pyrite. An interpreter that catches 
ALL undefined behavior, even in unsafe code:

    quarry miri

Detects:
  â€¢ All memory safety violations
  â€¢ Uninitialized memory reads
  â€¢ Invalid pointer arithmetic
  â€¢ Violating unsafe invariants
  â€¢ Even bugs sanitizers miss

Slower than sanitizers (10-100x) but exhaustive. Perfect for auditing unsafe 
code blocks.

Why Sanitizers Matter
~~~~~~~~~~~~~~~~~~~~~

This is table-stakes for "serious systems language":

  â€¢ Rust has Miri and sanitizer integration
  â€¢ C++ has ASan/TSan/UBSan (industry standard)
  â€¢ Go has race detector (built-in)
  â€¢ Zig is working toward similar tooling

Without sanitizers, Pyrite would seem "less serious" than competitors. With 
them, Pyrite becomes: "Memory-safe by design, verified by runtime checks, 
auditable with interpreters."

Real-world impact:
  â€¢ Chromium: ASan found 3,000+ bugs that code review missed
  â€¢ Rust: Miri caught soundness bugs in stdlib
  â€¢ Industry: Sanitizers are non-negotiable for security-critical code

Cost:
  â€¢ Zero runtime cost (only enabled for testing)
  â€¢ High confidence multiplier (catch what static analysis can't)
  â€¢ Required for safety certification in many domains

Implementation: Beta Release (fuzzing + ASan/TSan/UBSan via LLVM)
             Stable Release (Miri-equivalent interpreter)

8.10 Linting
--------------------------------------------------------------------------------

Multi-Level Linter
~~~~~~~~~~~~~~~~~~

quarry lint provides progressive strictness:

    quarry lint --level=beginner   # Gentle warnings, teaching mode
    quarry lint --level=standard   # Default, balanced
    quarry lint --level=pedantic   # Maximum strictness
    quarry lint --level=performance  # Focus on performance issues

Linter categories:

    Correctness:
      â€¢ Unused variables
      â€¢ Unreachable code
      â€¢ Type mismatches (if inference is ambiguous)
      â€¢ Pattern match exhaustiveness
    
    Style:
      â€¢ Naming conventions (snake_case, CamelCase)
      â€¢ Module organization
      â€¢ Public API documentation coverage
    
    Performance:
      â€¢ Heap allocations (see section 4.5)
      â€¢ Large copies
      â€¢ Unnecessary clones
      â€¢ Inefficient algorithms (e.g., O(nÂ²) where O(n) available)
    
    Safety:
      â€¢ Unsafe block auditing
      â€¢ FFI boundary checks
      â€¢ Concurrency patterns (potential deadlocks, etc.)

Customization
~~~~~~~~~~~~~

Project-level lint configuration in Quarry.toml:

    [lints]
    level = "standard"
    allow = ["large_copy"]      # Suppress specific warnings
    deny = ["heap_in_loop"]     # Elevate warnings to errors

8.10.1 Code Expansion: quarry expand
--------------------------------------------------------------------------------

To demystify compiler transformations and teach how high-level constructs desugar, 
Quarry provides quarry expand to show generated code:

Command Usage
~~~~~~~~~~~~~

    quarry expand file.pyrite              # Show all expansions
    quarry expand file.pyrite --function=foo  # Expand specific function
    quarry expand --closure-expansion      # Show parameter closure inlining

Use Cases
~~~~~~~~~

1. **Parameter closure expansion** - See how fn[...] is inlined:

   Source code:
       algorithm.vectorize[width=8](data.len(), fn[i: int]:
           data[i] = data[i] * 2.0
       )
   
   Expanded (quarry expand):
       const WIDTH = 8
       var i = 0
       
       # SIMD loop (parameter closure body inlined here)
       while i + WIDTH <= data.len():
           let vec = simd::Vec[f32, 8]::load(&data[i])
           let scaled = vec * 2.0
           scaled.store(&mut data[i])
           i += WIDTH
       
       # Remainder loop (parameter closure body inlined here)
       while i < data.len():
           data[i] = data[i] * 2.0  # Original closure body
           i += 1

2. **with statement desugaring** - See try + defer expansion:

   Source:
       with file = try File.open("config.txt"):
           process(file)
   
   Expanded:
       let file = try File.open("config.txt")
       defer:
           file.close()
       process(file)

3. **Compile-time parameter specialization:**

   Source:
       fn process[N: int](data: [u8; N]) -> int:
           # ...
       process[16](buffer)
   
   Expanded:
       # Specialized version for N=16
       fn process_16(data: [u8; 16]) -> int:
           # ... with N replaced by 16 ...

Teaching Benefits
~~~~~~~~~~~~~~~~~

quarry expand transforms abstract concepts into concrete code:

  â€¢ **Parameter closures:** "Here's exactly how it inlines"
  â€¢ **Zero-cost abstractions:** "See? No allocation, no indirection"
  â€¢ **Syntactic sugar:** "with desugars to try + defer"
  â€¢ **Compile-time params:** "Each [N] creates a specialized version"

Integration with Learning
~~~~~~~~~~~~~~~~~~~~~~~~~

Compiler errors suggest using expand:

    error[P0801]: cannot store parameter closure
      ...
      = help: Parameter closures are compile-time only (inlined)
      = explain: Run 'quarry expand --help closure-types' to see the difference
      = visual: Run 'quarry expand src/main.pyr --function=process' to see expansion

quarry learn exercises include expansion:

    Exercise: Understand Parameter Closures
    
    Run: quarry expand examples/vectorize.pyr
    
    See how the fn[i: int] closure is inlined into the SIMD loop.
    Notice: No function call, no allocation, just direct code insertion.

This makes abstract transformations concrete, accelerating learning.

Implementation: Beta Release (after parameter closures and sugar constructs are stable)

8.11 Documentation Generation
--------------------------------------------------------------------------------

Auto-Generated Docs
~~~~~~~~~~~~~~~~~~~

quarry doc generates HTML documentation from code and doc comments:

    """
    Parses a JSON string into a structured value.
    
    # Arguments
    * `input` - The JSON string to parse
    
    # Returns
    * `Ok(Value)` - Parsed JSON value
    * `Err(ParseError)` - Parse failure with error details
    
    # Examples
    ```pyrite
    let json = parse_json('{"key": "value"}')
    match json:
        Ok(val):
            print(val)
        Err(e):
            print("Parse error:", e)
    ```
    """
    fn parse_json(input: String) -> Result[Value, ParseError]:
        # Implementation

Generated docs include:
  â€¢ Public API reference
  â€¢ Example code (tested as part of doc tests)
  â€¢ Cross-links between related items
  â€¢ Search functionality
  â€¢ Source code links

8.12 Cross-Compilation
--------------------------------------------------------------------------------

First-Class Cross-Compilation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Quarry makes cross-compilation trivial:

    quarry build --target=aarch64-linux      # ARM64 Linux
    quarry build --target=x86_64-windows     # Windows x64
    quarry build --target=wasm32             # WebAssembly
    quarry build --target=arm-none-eabi      # Bare metal ARM

No separate toolchain setup required. Quarry downloads target-specific 
components automatically.

List available targets:

    quarry target list

Add target support:

    quarry target add riscv64-linux

Zero-Allocation Mode
~~~~~~~~~~~~~~~~~~~~

For embedded systems and safety-critical applications that require provable 
no-heap behavior, Quarry provides a zero-allocation build mode:

    quarry build --no-alloc
    
    # Or configure in Quarry.toml:
    [profile.embedded]
    no-alloc = true

In this mode, the compiler errors on any heap allocation:

    error[P0601]: heap allocation in no-alloc mode
      ----> src/main.pyr:42:13
       |
    42 |     let v = List[int].new()  # <---- allocates on heap
        |             ^^^^^^^^^^^^^^
        |
        = note: Build configured with --no-alloc
        = help: Use fixed-size array: [int; N]
        = help: Or pass pre-allocated buffer as parameter

What is forbidden:
  â€¢ List, Map, Set, String creation (heap containers)
  â€¢ Box[T], Rc[T], Arc[T] (heap allocation)
  â€¢ Dynamic trait objects (Box<dyn Trait>)
  â€¢ Any function marked with @may_alloc attribute

What is allowed:
  â€¢ Stack arrays: [int; 100]
  â€¢ Structs and enums (stack allocated)
  â€¢ References and slices
  â€¢ Static data and constants
  â€¢ Functions marked @noalloc

Example: Embedded firmware

    # Cargo.toml configuration
    [profile.embedded]
    no-alloc = true
    panic = "abort"
    opt-level = "z"  # Size optimization
    
    # main.pyrite
    @noalloc
    fn process_sensor_data(readings: &[u16; 32]) -> u32:
        var sum: u32 = 0
        for reading in readings:
            sum += reading as u32
        return sum / 32
    
    fn main():
        const BUFFER: [u16; 32] = [0; 32]
        loop:
            read_sensors(&mut BUFFER)
            let average = process_sensor_data(&BUFFER)
            display(average)

Benefits:
  â€¢ **Provable no-heap:** Compiler guarantees
  â€¢ **Safety certification:** Required for aerospace, medical devices
  â€¢ **Predictable memory:** No allocator = no allocation failures
  â€¢ **Minimal footprint:** No allocator code in binary

Integration with stdlib:
  â€¢ core:: namespace works in no-alloc mode
  â€¢ std:: namespace requires allocator
  â€¢ Clear documentation: "@requires alloc" on API docs

Use cases:
  â€¢ Microcontroller firmware (no MMU, limited RAM)
  â€¢ Real-time systems (deterministic memory)
  â€¢ Safety-critical software (aerospace, medical)
  â€¢ Bootloaders and kernels

This makes Pyrite credible for the most constrained embedded environments. 
Beta Release feature.

8.13 Cost Analysis and Performance Profiling
--------------------------------------------------------------------------------

Static Cost Analysis: quarry cost
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Beyond inline warnings, Pyrite provides structured cost analysis for IDE 
integration, CI/CD gates, and performance tracking.

Usage:

    quarry cost                     # Analyze entire project
    quarry cost --json              # Machine-readable output
    quarry cost --baseline=v1.json  # Compare against baseline
    quarry cost --threshold=warn    # Only show significant costs

Multi-Level Cost Reporting
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The quarry cost command supports progressive detail levels that match developer 
experience, teaching performance intuition gradually:

    quarry cost --level=beginner       # Gentle introduction
    quarry cost --level=intermediate   # Standard detail (default)
    quarry cost --level=advanced       # Comprehensive analysis

This mirrors the existing quarry lint --level pattern, creating a consistent 
mental model across tooling.

Beginner Level (--level=beginner)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Shows only high-level, actionable insights without overwhelming detail:

    Performance Analysis (Beginner)
    ================================
    
    ğŸ”¹ Your code allocates memory 12 times
       Most significant:
         â€¢ Line 234: Creates a list in a loop (runs 1000 times)
           â†’ Consider creating the list once before the loop
         â€¢ Line 156: Map grows dynamically
           â†’ Tip: Maps start small and grow as needed
    
    ğŸ”¹ Your code copies large data 3 times
         â€¢ Line 567: ImageBuffer (4 KB)
           â†’ Consider using a reference: &ImageBuffer
    
    ğŸ’¡ Learn more: run 'quarry cost --level=intermediate' for details

Beginner output characteristics:
  â€¢ Plain language (avoids jargon like "heap allocation", "amortized O(1)")
  â€¢ Only shows operations that matter (>1KB allocations, copies in loops)
  â€¢ Focuses on "what to do" not "why it happens"
  â€¢ Limits output to top 3-5 issues to avoid overwhelm

Intermediate Level (--level=intermediate, default)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Standard developer view with counts, sizes, and loop multiplication:

    Performance Analysis
    ====================
    
    Allocations: 12 sites (estimated 47 KB)
      
      ğŸ”´ Hot path (in loop):
        Line 234: List[Token].new()
          â€¢ Loop iterations: 1000
          â€¢ Per-call cost: 24 bytes (initial capacity)
          â€¢ Total cost: ~24 KB (may trigger 3-4 reallocations)
          â€¢ Suggestion: List[Token].with_capacity(100)
      
      ğŸŸ¡ Moderate:
        Line 156: Map[String, Config].insert()
          â€¢ Map capacity growth: 3 reallocations likely
          â€¢ Suggestion: with_capacity(estimated_entries)
    
    Copies: 3 sites (12 KB)
      Line 567: ImageBuffer (4096 bytes)
        â€¢ Passed by value to process_image()
        â€¢ Suggestion: Pass by reference (&ImageBuffer)
    
    ğŸ’¡ Run 'quarry cost --level=advanced' for dispatch and syscall analysis

Intermediate output characteristics:
  â€¢ Shows counts and sizes
  â€¢ Multiplies by loop iteration counts
  â€¢ Groups by severity (hot paths vs moderate)
  â€¢ Includes concrete suggestions with code examples

Advanced Level (--level=advanced)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Comprehensive analysis for performance-critical code:

    Performance Analysis (Advanced)
    ================================
    
    Allocations: 12 sites (47 KB estimated, 125 KB worst-case)
      
      ğŸ”´ Critical (hot path):
        src/parser.py:234:9 - List[Token].new()
          Function: parse_tokens() [called from 3 sites]
          Loop context: 0..1000 (bounded)
          Initial capacity: 24 bytes (6 elements)
          Growth pattern: 2x reallocation (typical usage: 15 elements)
          Expected reallocations: 2 (24â†’48â†’96 bytes)
          Total allocation cost: ~24 KB + 2 reallocations
          Suggestion: with_capacity(20) eliminates reallocations
          Allocator: DefaultHeap
      
      ğŸŸ¡ Moderate:
        src/cache.py:156:13 - Map[String, Config].insert()
          Growth: 0â†’16â†’32â†’64 entries (3 reallocations observed)
          Total cost: ~12 KB
          Frequency: Once per application startup
          Suggestion: with_capacity(50) if typical load known
    
    Copies: 3 sites (12 KB)
      src/renderer.py:567:14 - ImageBuffer
        Size: 4096 bytes
        Call chain: main() â†’ render_frame() â†’ process_image()
        Copy occurs: process_image(img: ImageBuffer)
        Suggestion: process_image(img: &ImageBuffer)
        Impact: 4KB memcpy per frame (60 FPS = 240 KB/sec)
    
    Dynamic Dispatch: 5 sites
      src/plugins.py:89:5 - Plugin::execute()
        Trait object: &dyn Plugin
        Virtual call overhead: ~2-3 cycles (indirect branch)
        Alternatives: enum dispatch, monomorphization
      
      src/events.py:234:10 - EventHandler::handle()
        Trait object: Box<dyn EventHandler>
        Pointer indirection: vtable lookup
        Context: Event loop (called frequently)
        Note: Acceptable cost for plugin architecture
    
    Syscalls: 23 sites
      File operations: 15 sites
        src/config.py:45 - File::open("/etc/app.conf")
        src/logger.py:89 - File::write() [buffered, ~10 syscalls/sec]
      
      Network operations: 8 sites
        src/api.py:156 - TcpStream::connect()
        src/api.py:234 - stream.read() [blocking I/O]
    
    Locking: 4 sites
      src/cache.py:67 - Mutex::lock()
        Hold time: <1Î¼s typical
        Contention: Low (single writer pattern)

Advanced output characteristics:
  â€¢ Full call chains and context
  â€¢ Detailed memory growth patterns
  â€¢ Allocator identification
  â€¢ Dynamic dispatch with vtable overhead estimates
  â€¢ Syscall breakdown by category
  â€¢ Lock contention analysis
  â€¢ Performance implications (e.g., "60 FPS = 240 KB/sec")

Level Selection Strategy
~~~~~~~~~~~~~~~~~~~~~~~~~

The tool automatically suggests level progression:
  â€¢ Beginner â†’ Intermediate: After user has addressed top issues
  â€¢ Intermediate â†’ Advanced: When optimizing hot paths or performance-critical code

IDE integration can show different levels in different contexts:
  â€¢ Inline hints: Beginner-level messages
  â€¢ Hover tooltips: Intermediate-level detail
  â€¢ "Show full analysis": Advanced-level deep dive

JSON Output Format:

    {
      "allocations": [
        {
          "location": "src/parser.py:234:9",
          "function": "parse_tokens",
          "type": "heap_allocation",
          "estimated_bytes": 1024,
          "frequency": "per_call",
          "suggestions": [
            "Pre-allocate with List.with_capacity(estimated_size)",
            "Reuse buffer across calls"
          ]
        }
      ],
      "copies": [
        {
          "location": "src/renderer.py:567:14",
          "bytes": 4096,
          "type": "ImageBuffer",
          "suggestion": "Pass by reference: &ImageBuffer"
        }
      ],
      "dynamic_dispatch": [
        {
          "location": "src/plugins.py:89:5",
          "trait": "Plugin",
          "method": "execute",
          "note": "Indirect call via vtable"
        }
      ],
      "syscalls": [
        {
          "location": "src/main.py:45:10",
          "operation": "file_open",
          "path": "/etc/config"
        }
      ],
      "summary": {
        "total_allocations": 47,
        "total_bytes_allocated": 125440,
        "total_copies": 12,
        "total_bytes_copied": 98304,
        "dynamic_dispatch_sites": 8,
        "syscall_sites": 23
      }
    }

IDE Integration:

IDEs can consume the JSON output to show inline cost hints:

    let tokens = List[Token].new()  ğŸ’° 1KB heap allocation
                                     âš¡ Hint: with_capacity(100)

CI/CD Integration:

Enforce performance budgets in continuous integration:

    # .github/workflows/ci.yml
    - name: Check performance budget
      run: |
        quarry cost --json > current.json
        quarry cost --baseline=baseline.json --threshold=error
        # Fails if allocations increased by >10%

Baseline tracking:

    quarry cost --save=baseline.json      # Save current as baseline
    quarry cost --compare=baseline.json   # Show differences

Example output:

    Performance Analysis
    ====================
    
    Allocations: 47 sites (125 KB estimated)
      â†‘ +3 sites since baseline
      â†‘ +12 KB since baseline
    
    Largest allocations:
      1. src/parser.py:234    8 KB  (in loop, 1000 iterations = 8 MB)
      2. src/cache.py:156     4 KB  (Map growth)
      3. src/buffer.py:89     2 KB  (String concatenation)
    
    Copies: 12 sites (96 KB total)
      â†’ src/renderer.py:567   4 KB  ImageBuffer
      â†’ src/config.py:123     8 KB  ConfigData
    
    Dynamic dispatch: 8 sites
      â†’ All in plugin system (expected)
    
    Syscalls: 23 sites
      â†’ 15 file operations
      â†’ 8 network operations

Use Cases:

1. **Performance debugging:** Find unexpected allocations
2. **CI gates:** Prevent performance regressions
3. **Optimization tracking:** Measure improvement over time
4. **IDE hints:** Show costs inline while coding
5. **Code review:** Highlight performance-sensitive changes

This completes Pyrite's cost-transparency story: from inline warnings (for 
developers) to structured reports (for tools and CI systems).

Runtime Performance Profiling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Static analysis (quarry cost) shows what *could* be expensive. Runtime profiling 
shows what *is* expensive in actual execution. Quarry provides integrated 
profiling commands that complement static cost analysis:

quarry perf - Flamegraph Profiling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Integrated CPU profiling with flamegraph visualization:

    quarry perf                         # Profile with default settings
    quarry perf --release               # Profile optimized build
    quarry perf --output=profile.svg    # Export flamegraph
    quarry perf --duration=30s          # Profile for 30 seconds

Under the hood:
  â€¢ Linux: Wraps perf with optimal sampling settings
  â€¢ macOS: Wraps Instruments DTrace profiler
  â€¢ Windows: Wraps ETW (Event Tracing for Windows)
  â€¢ Generates interactive flamegraph SVG automatically

Output shows:
  â€¢ CPU time spent in each function
  â€¢ Call stack context (who called what)
  â€¢ Hot paths highlighted
  â€¢ Standard flamegraph format (widely recognized)

Example workflow:

    $ quarry perf --release
    Profiling myapp (optimized build)...
    Captured 45,234 samples over 10.2 seconds
    
    Top functions by CPU time:
      34.2%  process_data
      18.5%  parse_input
      12.3%  allocate_buffers
    
    Flamegraph saved to: target/profile.svg
    Open in browser to explore call stacks

quarry alloc - Allocation Profiling
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Track heap allocations with call stack context:

    quarry alloc                        # Profile allocations
    quarry alloc --threshold=1KB        # Only show allocations > 1KB
    quarry alloc --json                 # Machine-readable output

Shows:
  â€¢ Every heap allocation with size
  â€¢ Call stack that triggered allocation
  â€¢ Allocation hot spots (frequency Ã— size)
  â€¢ Reallocation events (growth patterns)

Example output:

    Allocation Profile
    ==================
    
    Total allocations: 1,247 (2.4 MB)
    
    Hot spots (by total bytes):
      1. src/parser.py:234 - List[Token].new()
         â€¢ 1,000 allocations (24 KB each = 24 MB total)
         â€¢ Call chain: parse() â†’ tokenize() â†’ List::new()
         â€¢ Suggestion: Pre-allocate with with_capacity(1000)
      
      2. src/cache.py:156 - Map[String, Config].insert()
         â€¢ 47 allocations (growth: 16â†’32â†’64â†’128 entries)
         â€¢ Total: 12 KB
         â€¢ Suggestion: with_capacity(128) eliminates reallocations
    
    Allocation timeline:
      0-1s:    234 allocations (456 KB)
      1-2s:    189 allocations (378 KB)
      2-3s:    824 allocations (1.6 MB) â† spike here

Integration with quarry cost:
  â€¢ Static analysis predicts allocations
  â€¢ Runtime profiling confirms actual behavior
  â€¢ Cross-reference: "quarry cost predicted 12 sites, profiler found 11"

quarry pgo - Profile-Guided Optimization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One-command PGO pipeline automates the 3-step process:

    quarry pgo                          # Build â†’ train â†’ rebuild
    quarry pgo --workload=bench         # Use benchmarks as training
    quarry pgo --workload="./train.sh"  # Custom training script

Manual PGO Workflow (Full Control)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For custom training workloads or complex scenarios, use the explicit 3-step workflow:

    # Step 1: Build instrumented binary
    $ quarry pgo generate
    Building instrumented binary for PGO training...
    âœ“ Built: target/pgo-instrument/myapp
    âœ“ Profile output: target/pgo-data/default.profraw
    
    Instrumentation:
      â€¢ Functions: 1,247 instrumented
      â€¢ Basic blocks: 12,456 tracked
      â€¢ Binary size: 3.2 MB (1.5x larger than release)
    
    Next: Run your training workload with this binary
          ./target/pgo-instrument/myapp [your args]
    
    # Step 2: Run training workload (your application-specific usage)
    $ ./target/pgo-instrument/myapp --benchmark
    # Or: ./target/pgo-instrument/myapp < typical_input.txt
    # Or: python run_training_suite.py
    # (Profile data automatically written to target/pgo-data/)
    
    # Step 3: Build optimized binary with profile data
    $ quarry pgo optimize
    Building with profile-guided optimization...
    âœ“ Analyzed profile data: target/pgo-data/default.profraw
    âœ“ Built: target/release/myapp
    
    PGO Optimizations Applied:
      â€¢ Functions inlined: 89 (based on hot paths)
      â€¢ Functions outlined: 45 (based on cold paths)
      â€¢ Branch weights: 1,234 basic blocks reordered
      â€¢ Code layout: Hot code grouped for cache locality
    
    Performance improvement:
      â€¢ Estimated: 15-30% faster on training workload
      â€¢ Binary size: 2.0 MB (cold code moved out-of-line)
    
    Next: Benchmark the optimized binary
          quarry bench --compare-to=baseline

Multiple Training Runs:

    # Collect profile data from multiple workloads
    $ quarry pgo generate
    
    $ ./target/pgo-instrument/myapp --workload=web_server
    # Profile data: target/pgo-data/run1.profraw
    
    $ ./target/pgo-instrument/myapp --workload=batch_processing
    # Profile data: target/pgo-data/run2.profraw
    
    $ ./target/pgo-instrument/myapp --workload=interactive
    # Profile data: target/pgo-data/run3.profraw
    
    # Merge all profiles and optimize
    $ quarry pgo optimize --merge-all
    Merging 3 profile datasets...
    âœ“ Combined profile represents all workloads
    Building optimized binary...

Clean up profile data:

    quarry pgo clean                       # Remove profile data
    quarry pgo reset                       # Reset and start over

Automated PGO Workflow (One Command)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For simple cases with standard workloads:

    quarry pgo                          # Build â†’ train â†’ rebuild
    quarry pgo --workload=bench         # Use benchmarks as training
    quarry pgo --workload="./train.sh"  # Custom training script

Automated workflow:
  1. quarry pgo
     â†’ Builds instrumented binary
     â†’ Runs typical workload (or prompts for one)
     â†’ Rebuilds optimized binary
     â†’ Reports performance improvement

Example:

    $ quarry pgo --workload=bench
    
    Step 1/3: Building instrumented binary...
    âœ“ Built target/pgo-instrument/myapp
    
    Step 2/3: Running training workload (benchmarks)...
    âœ“ Collected profile data from 5 benchmarks
    
    Step 3/3: Rebuilding with profile-guided optimization...
    âœ“ Built target/release/myapp
    
    Performance improvement:
      â€¢ 15% faster on parse_large_file benchmark
      â€¢ 8% faster on compute_heavy benchmark
      â€¢ Binary size: 2.1 MB â†’ 2.0 MB (branch pruning)

Why PGO matters:
  â€¢ Optimizes for actual code paths (not theoretical ones)
  â€¢ Better inlining decisions (inline hot paths, not cold ones)
  â€¢ Better branch prediction hints
  â€¢ Can yield 10-30% performance improvement

Quarry automates the tedious parts while giving control when needed.

LTO and Combined Optimization Workflows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Link-Time Optimization (LTO) enables cross-translation-unit optimization by 
deferring code generation to link time. Quarry provides first-class LTO support 
with simple flags:

    quarry build --release --lto        # Full LTO (maximum optimization)
    quarry build --release --lto=thin   # Thin LTO (faster builds, good optimization)

LTO modes:
  â€¢ --lto or --lto=full - Full link-time optimization
    â€¢ Optimizes across all translation units
    â€¢ Slowest build times (minutes for large projects)
    â€¢ Best optimization (5-15% improvement typical)
    â€¢ Use for: Final release builds, benchmarking
  
  â€¢ --lto=thin - Thin LTO (recommended default for --release)
    â€¢ Fast incremental builds with cross-module optimization
    â€¢ 80% of full LTO benefit at 20% of compile time cost
    â€¢ Enables parallel optimization
    â€¢ Use for: Iterative optimization, CI builds
  
  â€¢ No LTO - Fastest builds, per-module optimization only
    â€¢ Use for: Debug builds, development iteration

Combined workflow for maximum performance:

    quarry build --release --lto=thin --pgo=./workload.sh
    
    # Combines:
    # 1. Release optimizations (--O3 equivalent)
    # 2. Thin LTO (cross-module inlining and optimization)
    # 3. Profile-guided optimization (optimize for actual usage)
    
    Typical results:
      â€¢ Release alone: 10x faster than debug
      â€¢ + Thin LTO: 15-25% additional improvement
      â€¢ + PGO: 10-30% additional improvement
      â€¢ Combined: 15-50% faster than plain release

One-command peak performance:

    quarry build --peak
    
    # Equivalent to: --release --lto --pgo=bench
    # Automatically:
    #   1. Builds with thin LTO + instrumentation
    #   2. Runs benchmark suite as PGO training
    #   3. Rebuilds with full LTO + PGO data
    #   4. Reports achieved optimization levels
    
    Output:
      Peak Performance Build
      ======================
      
      Step 1/3: Building instrumented binary (thin LTO)...
      âœ“ Built in 2m 34s
      
      Step 2/3: Training with benchmark workload...
      âœ“ Collected profile from 12 benchmarks (45s)
      
      Step 3/3: Final build (full LTO + PGO)...
      âœ“ Built in 8m 12s
      
      Optimizations applied:
        â€¢ Release optimizations: baseline
        â€¢ Thin LTO (training): +18% performance
        â€¢ Full LTO (final): +7% performance
        â€¢ PGO: +23% performance
        â€¢ Total improvement: +55% vs release
      
      Binary: target/peak/myapp (2.3 MB)
      Recommended for: Production deployment

Build profiles can configure defaults:

    # Quarry.toml
    [profile.release]
    opt-level = 3
    lto = "thin"        # Enable thin LTO for release builds
    pgo = false         # Manual PGO only
    
    [profile.peak]
    inherits = "release"
    lto = "full"        # Full LTO for peak builds
    pgo = true          # Always run PGO
    pgo-workload = "bench"

Comparison table:

    | Build Mode         | Time | Binary Size | Performance | Use Case               |
    |--------------------|------|-------------|-------------|------------------------|
    | Debug              | 10s  | 5 MB        | 1x          | Development            |
    | --release          | 30s  | 2 MB        | 10x         | Testing                |
    | --release --lto    | 2m   | 1.8 MB      | 12x         | Distribution           |
    | --release --pgo    | 5m   | 2 MB        | 13x         | Optimized for workload |
    | --peak             | 10m  | 1.8 MB      | 15x         | Production max perf    |

When to use each:
  â€¢ Debug: Iteration, debugging
  â€¢ Release: QA, most users
  â€¢ Release + thin LTO: Distribution default (good balance)
  â€¢ Peak: Mission-critical services, performance benchmarking

Cost transparency:

    quarry cost shows optimization decisions:
      
      Build: --release --lto --pgo
      
      Optimizations applied:
        â€¢ 1,234 functions inlined (cross-module via LTO)
        â€¢ 89 cold paths moved out-of-line (via PGO)
        â€¢ 234 branches reordered (via PGO branch weights)
        â€¢ 45 functions specialized (hot path variants)
      
      Estimated improvements:
        â€¢ LTO: +18% (reduced call overhead)
        â€¢ PGO: +23% (optimized for actual workload)

Why this matters:

LTO and PGO are proven optimizations that yield 20-50% improvements in real-world 
applications, but are often tedious to configure. Quarry makes them one-command 
operations, and --peak mode makes "absolute best performance" a single flag.

Beta Release feature (LTO support). Beta Release enhancement (--peak command).

quarry tune - Intelligent Optimization Suggestions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Correlates static analysis (quarry cost) with runtime profiling (quarry perf, 
quarry alloc) to suggest specific, high-impact optimizations:

    quarry tune                         # Analyze and suggest
    quarry tune --apply                 # Apply safe suggestions automatically
    quarry tune --interactive           # Review each suggestion

Example output:

    Performance Tuning Suggestions
    ===============================
    
    Based on static analysis and runtime profiling:
    
    ğŸ”´ HIGH IMPACT (3 suggestions)
    
    1. Pre-allocate List in hot loop
       Location: src/parser.py:234
       
       Current code:
         for line in lines:              # 1000 iterations
             let tokens = List[Token].new()
       
       Issue:
         â€¢ Static analysis: Allocates in loop (1000 times)
         â€¢ Runtime profile: 24 MB allocated, 3-4 reallocations per list
         â€¢ CPU time: 12% of total runtime
       
       Suggested fix:
         let tokens = List[Token].with_capacity(20)
         for line in lines:
             tokens.clear()
             # ... use tokens ...
       
       Expected improvement:
         â€¢ Eliminates 1000 allocations
         â€¢ Removes all reallocations
         â€¢ Estimated speedup: 15-20%
       
       [Apply] [Skip] [Explain]
    
    2. Pass ImageBuffer by reference
       Location: src/renderer.py:567
       
       Current code:
         fn process_image(img: ImageBuffer):  # Takes ownership, copies 4 KB
       
       Issue:
         â€¢ Static analysis: 4 KB copy on every call
         â€¢ Runtime profile: Called 60 times/second (240 KB/sec copied)
         â€¢ CPU time: 8% of total runtime
       
       Suggested fix:
         fn process_image(img: &ImageBuffer):  # Borrows, no copy
       
       Expected improvement:
         â€¢ Eliminates 4 KB copy per frame
         â€¢ Estimated speedup: 8-10%
       
       [Apply] [Skip] [Explain]
    
    ğŸŸ¡ MEDIUM IMPACT (5 suggestions)
    
    3. Use SmallVec for small arrays
       Location: src/ast.py:89
       [Details...]
    
    [Show all] [Apply all safe fixes] [Cancel]

How quarry tune works:
  1. Runs static cost analysis (quarry cost)
  2. Runs runtime profiling (quarry perf + quarry alloc)
  3. Correlates findings: "This allocation was predicted and IS a hot spot"
  4. Ranks by impact: CPU time Ã— memory Ã— frequency
  5. Suggests specific, actionable fixes
  6. Can apply safe transformations automatically

Why this is transformative:
  â€¢ Beginners: "Just run quarry tune" â†’ get specific guidance
  â€¢ Experts: Saves manual correlation work
  â€¢ Actionable: Not generic advice, specific line numbers + code changes
  â€¢ Measurable: Estimates improvement (based on profiling data)

This completes the performance tooling story:
  â€¢ quarry cost: Static "what could be expensive"
  â€¢ quarry perf: Runtime "what is expensive (CPU)"
  â€¢ quarry alloc: Runtime "what is expensive (memory)"
  â€¢ quarry pgo: Optimize for actual workloads
  â€¢ quarry tune: Correlate all data, suggest fixes

Performance Lockfile: Enforced "Fast Forever"
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The performance lockfile workflow transforms Pyrite's cost transparency from 
"measure performance" to "enforce performance stays constant." This is the 
missing piece that turns "Pyrite is fast" into "Pyrite stays fast forever."

Command Usage
~~~~~~~~~~~~~

    quarry perf --baseline              # Write Perf.lock
    quarry perf --check                 # Fail CI if regressed
    quarry perf --check --threshold=5%  # Custom regression tolerance
    quarry perf --diff                  # Show differences vs baseline

Performance Lockfile Creation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Generate a baseline snapshot of performance characteristics:

    $ quarry perf --baseline
    
    Profiling optimized build...
    Running benchmark suite (12 benchmarks)...
    
    Performance Baseline Generated
    ===============================
    
    Hot Functions (saved to Perf.lock):
      â€¢ process_data: 1247ms (34.2% total time)
        - SIMD width: 8 (AVX2)
        - Inlined: 23 callsites
        - Allocation sites: 3
      
      â€¢ parse_input: 674ms (18.5% total time)
        - Call count: 10,247
        - Allocation sites: 12
        - Stack usage: 4 KB
      
      â€¢ allocate_buffers: 448ms (12.3% total time)
        - Heap allocations: 47 sites
        - Total allocated: 125 KB
    
    Optimization Baseline:
      â€¢ Total allocations: 47 sites (125 KB)
      â€¢ SIMD width used: 8 (AVX2)
      â€¢ Inlining decisions: 1,234 functions
      â€¢ Code generation: optimized
    
    Baseline saved to: Perf.lock
    Commit this file to track performance over time

Perf.lock Format
~~~~~~~~~~~~~~~~

The lockfile stores concrete, measurable performance metrics:

    # Perf.lock (YAML format for readability)
    version: "1.0"
    generated: "2025-12-18T10:30:00Z"
    build: "--release --lto=thin"
    platform: "x86_64-linux"
    
    hot_functions:
      - name: "process_data"
        time_ms: 1247
        time_percent: 34.2
        simd_width: 8
        inlined_calls: 23
        alloc_sites: 3
      
      - name: "parse_input"
        time_ms: 674
        time_percent: 18.5
        call_count: 10247
        alloc_sites: 12
        stack_bytes: 4096
    
    allocations:
      total_sites: 47
      total_bytes: 125440
      hot_spots:
        - location: "src/parser.py:234"
          count: 1000
          bytes_per: 24
    
    optimizations:
      functions_inlined: 1234
      simd_vectorized: 67
      loops_unrolled: 23

CI Integration and Regression Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In continuous integration, enforce performance constraints:

    $ quarry perf --check
    
    Checking performance against baseline (Perf.lock)...
    
    âœ— PERFORMANCE REGRESSION DETECTED
    
    Regressions (threshold: 5%):
    
      ğŸ”´ CRITICAL: process_data regressed by 18%
         Baseline: 1247ms â†’ Current: 1471ms (+224ms)
         
         Analysis:
           â€¢ SIMD width changed: 8 (AVX2) â†’ 4 (SSE2)
           â€¢ Reason: Alignment check now fails
           â€¢ Affected code: src/process.py:156-189
         
         Run 'quarry perf --explain process_data' for details
      
      ğŸŸ¡ WARNING: parse_input regressed by 6.2%
         Baseline: 674ms â†’ Current: 716ms (+42ms)
         
         Analysis:
           â€¢ New allocation added: src/parser.py:241
           â€¢ Inlining stopped: tokenize() no longer inlined
           â€¢ Reason: Function grew beyond inlining threshold
         
         Run 'quarry perf --explain parse_input' for details
    
    Summary:
      â€¢ 2 functions regressed
      â€¢ 0 functions improved
      â€¢ Overall regression: 11.3% slower
    
    CI FAILURE: Performance regressions exceed threshold
    Exit code: 1

This output is actionable: developers know exactly which function regressed, 
by how much, and WHY (SIMD width changed, inlining stopped, allocation added).

Explaining Regressions
~~~~~~~~~~~~~~~~~~~~~~~

Deep-dive into why performance changed:

    $ quarry perf --explain process_data
    
    Performance Regression Analysis: process_data
    ==============================================
    
    Baseline: 1247ms (34.2% of runtime)
    Current:  1471ms (38.9% of runtime)
    Change:   +224ms (+18% slower) âš ï¸
    
    Root Causes:
    
    1. SIMD Width Reduced (PRIMARY CAUSE)
       
       Baseline: 8-wide SIMD (AVX2)
         â€¢ Vectorized loop at line 156
         â€¢ Processes 8 f32 per iteration
         â€¢ Generated: vfmadd231ps (AVX2 FMA instruction)
       
       Current: 4-wide SIMD (SSE2)
         â€¢ Same loop now uses SSE2
         â€¢ Processes 4 f32 per iteration
         â€¢ Generated: mulps + addps (SSE2 instructions)
       
       Why the change?
         â€¢ Buffer alignment changed from 32-byte to 16-byte
         â€¢ Change introduced in: commit abc123f
         â€¢ File: src/buffers.py:89
         â€¢ Old: #[align(32)] â†’ New: #[align(16)]
       
       Fix:
         Restore 32-byte alignment for AVX2:
           struct Buffer:
               #[align(32)]  # Required for 8-wide SIMD
               data: [f32; 1024]
    
    2. Inlining Stopped (SECONDARY CAUSE)
       
       Baseline: compute_kernel() inlined at 23 callsites
       Current:  compute_kernel() NOT inlined (function call overhead)
       
       Why?
         â€¢ Function body grew from 45 â†’ 89 instructions
         â€¢ Exceeded inlining threshold (80 instructions)
         â€¢ Change: Added debug logging in commit def456
       
       Fix:
         Remove debug logging in hot path, or use:
           @always_inline
           fn compute_kernel(...):

Assembly Diff (Optional)
~~~~~~~~~~~~~~~~~~~~~~~~

For expert debugging, show assembly differences:

    $ quarry perf --diff-asm process_data
    
    Assembly Diff: process_data (Baseline vs Current)
    ==================================================
    
    Baseline (AVX2, 8-wide SIMD):
      vmovups ymm0, [rdi + 0]      ; Load 8 f32
      vmovups ymm1, [rsi + 0]      ; Load 8 f32
      vfmadd231ps ymm0, ymm1, ymm2 ; FMA: ymm0 += ymm1 * ymm2
      vmovups [rdx + 0], ymm0      ; Store 8 f32
      add rdi, 32                  ; Advance pointer
      add rsi, 32
      add rdx, 32
    
    Current (SSE2, 4-wide SIMD):
      movups xmm0, [rdi + 0]       ; Load 4 f32
      movups xmm1, [rsi + 0]       ; Load 4 f32
      mulps xmm1, xmm2             ; Multiply
      addps xmm0, xmm1             ; Add
      movups [rdx + 0], xmm0       ; Store 4 f32
      add rdi, 16                  ; Advance pointer
      add rsi, 16
      add rdx, 16
    
    Analysis:
      â€¢ Twice as many loop iterations (8â†’4 elements per iter)
      â€¢ No FMA instruction (requires 2 ops instead of 1)
      â€¢ Estimated: 2x slower per element processed

IR Diff (Alternative)
~~~~~~~~~~~~~~~~~~~~~~

For compiler developers, show LLVM IR differences:

    $ quarry perf --diff-ir process_data
    
    Shows side-by-side LLVM IR with:
      â€¢ Vectorization decisions
      â€¢ Inlining decisions
      â€¢ Optimization passes applied
      â€¢ Differences highlighted

Why Performance Lockfile Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This workflow addresses the critical "performance decay" problem:

Without lockfile:
  â€¢ Performance regressions silent until users complain
  â€¢ Root cause requires manual profiling and assembly inspection
  â€¢ Team doesn't know WHICH commit caused slowdown
  â€¢ Optimization decisions lost to history

With lockfile:
  â€¢ CI fails immediately on regression
  â€¢ Exact function and root cause identified
  â€¢ Assembly/IR diff shows what changed
  â€¢ Actionable fix suggestions provided
  â€¢ Performance becomes a first-class requirement like tests

Real-World Impact:
  â€¢ Chromium: 20% of commits have measurable performance impact
  â€¢ Without gates: Performance decays 2-3% per month (death by 1000 cuts)
  â€¢ With gates: Performance stays constant or improves

This is how you turn "Pyrite is fast" (snapshot) into "Pyrite stays fast 
forever" (guarantee). It's the missing enforcement layer for cost transparency.

Implementation Strategy
~~~~~~~~~~~~~~~~~~~~~~~

Beta Release addition (after quarry cost and quarry perf are stable):

1. **Baseline generation:** Extend quarry perf to save structured snapshot
2. **CI checking:** Add --check mode that compares against Perf.lock
3. **Regression analysis:** Correlate with compiler optimization decisions
4. **Assembly diff:** Use objdump + diff for concrete evidence
5. **IR diff:** Optional LLVM IR comparison for compiler developers

Storage format:
  â€¢ Perf.lock committed to version control (like Cargo.lock)
  â€¢ Machine-readable (YAML or JSON) for tooling
  â€¢ Human-readable for code review

Threshold configuration:

    # Quarry.toml
    [perf]
    threshold = 5              # Fail CI if >5% slower
    threshold-critical = 10    # Hard failure threshold
    baseline = "Perf.lock"     # Default baseline file
    
    [perf.functions]
    "process_data" = 2         # Critical function: 2% tolerance
    "parse_input" = 10         # Less critical: 10% tolerance

This provides the highest-leverage addition to Pyrite's existing performance 
tooling.

8.14 Interactive Learning: quarry learn
--------------------------------------------------------------------------------

Pyrite includes a built-in interactive learning system inspired by Rustlings. 
The quarry learn command provides structured exercises that teach concepts 
through practice.

Command Usage
~~~~~~~~~~~~~

    quarry learn                   # Start interactive tutorial
    quarry learn ownership         # Jump to specific topic
    quarry learn --list            # Show all available topics
    quarry learn --reset           # Reset progress

Topics covered:
  â€¢ Basics: Variables, functions, control flow
  â€¢ Ownership: Moves, borrowing, lifetimes
  â€¢ Types: Structs, enums, pattern matching
  â€¢ Collections: List, Map, iteration
  â€¢ Error handling: Result types, try operator
  â€¢ Concurrency: Threads, channels, mutexes
  â€¢ Performance: SIMD, vectorization, profiling
  â€¢ Advanced: Generics, traits, metaprogramming

Interactive Exercise Format
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each exercise presents broken code that the learner must fix:

    $ quarry learn ownership
    
    ============================================================
    Exercise: Ownership 3/12 - Borrowing Rules
    ============================================================
    
    Fix the code below to satisfy the borrow checker.
    The function should process data without taking ownership.
    
    File: exercises/ownership_03.pyrite
    
        fn main():
            let data = List[int]([1, 2, 3])
            process(data)
            print(data.length())  # Error: value was moved
        
        fn process(list: List[int]):
            print("Processing...")
    
    ============================================================
    
    Try to fix it! Then run:
      quarry learn check
    
    Hint: Use & to borrow instead of moving
    Stuck? Run: quarry learn hint

Workflow:
  1. Read exercise description
  2. Edit exercise file in your editor
  3. Run quarry learn check to verify solution
  4. Get instant feedback (pass/fail + explanation)
  5. Move to next exercise automatically

Example check output:

    $ quarry learn check
    
    âœ“ Code compiles successfully!
    âœ“ Ownership rules satisfied
    âœ“ Test cases pass
    
    Great job! You've learned:
      â€¢ How to borrow data with &T
      â€¢ When to use borrowing vs. moving
      â€¢ How to keep data usable after function calls
    
    Key concept:
      Borrowing (&) lets functions access data without taking ownership.
      The original owner retains the value and can use it after the call.
    
    Next exercise: ownership_04.pyrite (mutable borrowing)
    
    Progress: 3/12 ownership exercises complete
    Run 'quarry learn next' to continue

Hints System
~~~~~~~~~~~~

Progressive hints prevent frustration without spoiling solutions:

    $ quarry learn hint
    
    Hint 1/3:
      The problem is that 'process' takes ownership of 'list'.
      After the call, 'data' is no longer valid in 'main'.
    
    Press Enter for next hint, or Ctrl+C to try again...
    
    Hint 2/3:
      Change the function signature to borrow instead:
        fn process(list: &List[int])
    
    Press Enter for next hint...
    
    Hint 3/3 (SOLUTION):
      Change line 5 to:
        fn process(list: &List[int]):
      
      And line 3 to:
        process(&data)

Hints are spaced to encourage thinking before revealing solutions.

Progress Tracking
~~~~~~~~~~~~~~~~~

Learners can track their journey:

    $ quarry learn status
    
    Your Pyrite Learning Progress
    ==============================
    
    âœ“ Basics          [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 12/12 (100%)
    âœ“ Ownership       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘]  8/12 (67%)
    â–‘ Types           [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  2/10 (20%)
    â–‘ Collections     [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  0/8  (0%)
    â–‘ Error Handling  [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  0/6  (0%)
    
    Current: ownership_09.pyrite (Lifetime basics)
    
    Estimated time to complete Ownership: 1.5 hours
    
    Run 'quarry learn next' to continue

Progress saved locally (~/.cache/pyrite/learn/progress.json).

Topic Deep-Dives
~~~~~~~~~~~~~~~~

Some topics include mini-projects:

    $ quarry learn ownership --project
    
    ============================================================
    Ownership Final Project: Build a Simple Text Editor Buffer
    ============================================================
    
    Apply everything you've learned to build a text buffer that:
      â€¢ Stores lines of text efficiently
      â€¢ Allows insertion and deletion
      â€¢ Provides undo/redo functionality
      â€¢ Manages memory safely without leaks
    
    Starter code: exercises/projects/text_buffer/
    
    Requirements:
      âœ“ Pass all 15 test cases
      âœ“ No memory leaks (quarry test --leak-check)
      âœ“ No unsafe code blocks
      âœ“ Efficient (< 100ms for 10,000 operations)
    
    This project synthesizes:
      â€¢ Ownership and borrowing
      â€¢ Mutable references
      â€¢ Collections (Vec, String)
      â€¢ Error handling
    
    Good luck! Run 'quarry test' to check your implementation.

Projects provide synthesis opportunities and build confidence.

Integration with Error Messages
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The learning system connects to the compiler:

When you encounter error P0234 in real code:

    error[P0234]: cannot use moved value 'data'
      ...
      = learn: Run 'quarry learn ownership' for interactive practice
      = explain: Run 'pyritec --explain P0234' for detailed explanation

This creates a learning loop:
  1. Hit error in real code
  2. Compiler suggests relevant exercises
  3. Practice concept in isolation
  4. Return to real code with understanding

Why quarry learn Matters
~~~~~~~~~~~~~~~~~~~~~~~~~

Interactive learning addresses the "Rust is hard" perception:

  â€¢ **Structured path:** Clear progression from basics to advanced
  â€¢ **Hands-on practice:** Learn by fixing code, not reading theory
  â€¢ **Immediate feedback:** Know instantly if you got it right
  â€¢ **Progressive hints:** Never stuck, never spoiled
  â€¢ **Synthesis projects:** Apply concepts in realistic scenarios

Research shows interactive practice > passive reading for systems concepts. 
Rustlings (Rust's equivalent) is consistently praised as the best way to learn 
ownership.

Pyrite adopts this proven approach as a first-class feature, making the learning 
curve feel manageable instead of insurmountable.

Stable Release Feature
~~~~~~~~~~~~~~~

quarry learn is implemented in Stable Release (Developer Experience) after the core 
compiler and error messages are stable. It depends on:
  â€¢ Excellent error messages (to teach through failures)
  â€¢ quarry test framework (to verify solutions)
  â€¢ pyritec --explain system (for deep dives)

Once available, it becomes the recommended path for all newcomers: "Install 
Pyrite, run quarry learn, build real projects with confidence."

8.15 Integration and CI/CD
--------------------------------------------------------------------------------

CI-Friendly Commands
~~~~~~~~~~~~~~~~~~~~

Quarry provides non-interactive, CI-optimized commands:

    quarry build --locked          # Fail if Quarry.lock is outdated
    quarry test --no-fail-fast     # Run all tests, report all failures
    quarry fmt --check             # Verify formatting without changes
    quarry audit                   # Check for security vulnerabilities

Example GitHub Actions workflow:

    name: CI
    on: [push, pull_request]
    jobs:
      test:
        runs-on: ubuntu-latest
        steps:
          - uses: actions/checkout@v2
          - uses: pyrite-lang/setup-quarry@v1
          - run: quarry fmt --check
          - run: quarry lint
          - run: quarry test
          - run: quarry build --release

8.16 Edition System and Stability
--------------------------------------------------------------------------------

Pyrite uses an Edition system to enable language evolution without breaking 
existing code. This is a critical trust signal for developers betting careers 
and projects on the language.

What are Editions?
~~~~~~~~~~~~~~~~~~

Editions are opt-in milestones that introduce backward-compatible changes to 
syntax, lints, and language defaults. Code written in one edition continues to 
work with newer compilers indefinitely.

Key principles:

  â€¢ **Backward compatibility:** Pyrite 2028 compiler compiles 2025 code
  â€¢ **Forward migration:** Automated tools upgrade code between editions
  â€¢ **Semantic versioning:** Editions released every 3 years (2025, 2028, 2031...)
  â€¢ **ABI stability:** Editions never break binary compatibility
  â€¢ **Interoperability:** Libraries from different editions work together

Declaring Edition
~~~~~~~~~~~~~~~~~

Projects declare their edition in Quarry.toml:

    [package]
    name = "myproject"
    version = "0.1.0"
    edition = "2025"          # Explicitly declares edition

Scripts without Quarry.toml use the latest stable edition at compilation time.

What Can Change Between Editions?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Editions can introduce:

1. **New syntax sugar:**
   - Edition 2025: `&T` for references
   - Edition 2028: Might add `?T` sugar for `Optional[T]`
   - Old code still uses `Optional[T]`, new code can choose

2. **New keywords:**
   - Edition 2028 might reserve `async` as keyword
   - 2025 code using `async` as identifier still compiles in 2025 mode

3. **Lint defaults:**
   - Edition 2028 might make certain warnings errors by default
   - 2025 code still uses 2025 lint levels

4. **Standard library additions:**
   - New modules available in all editions
   - Backward compatible only

What CANNOT Change:
  âœ— Core semantics (ownership rules remain stable)
  âœ— Type system fundamentals
  âœ— ABI/calling conventions
  âœ— Binary format
  âœ— Unsafe behavior definitions

Migration Between Editions
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Quarry provides automatic migration tooling:

    # Check if code is ready for new edition
    quarry edition check --target=2028
    
    # Preview migration changes
    quarry edition migrate --edition=2028 --dry-run
    
    # Apply migration
    quarry edition migrate --edition=2028
    
    # Fix any remaining issues interactively
    quarry fix --edition=2028

Migration is typically straightforward:
  â€¢ Rename identifiers that became keywords
  â€¢ Apply automatic syntax transformations
  â€¢ Update lint suppressions if needed

Example migration output:

    Migrating from Edition 2025 to Edition 2028
    ============================================
    
    Found 3 changes needed:
    
    1. src/main.pyrite:45
       Identifier 'async' is now a keyword
       â†’ Rename to 'async_operation'
    
    2. src/parser.pyrite:123
       Deprecated syntax: match x: case 1: ...
       â†’ New syntax: match x { 1 => ... }
    
    3. Lints now error by default:
       - unused_variables (was warning)
       - large_copy (was allow)
    
    Apply changes? [Y/n]

Mixed-Edition Projects
~~~~~~~~~~~~~~~~~~~~~~

Dependencies can use different editions:

    [package]
    edition = "2028"
    
    [dependencies]
    parser = "1.0"      # Uses edition 2025 internally
    json = "2.0"        # Uses edition 2028

The compiler bridges editions automatically. Binary interfaces remain 
compatible.

Edition Schedule
~~~~~~~~~~~~~~~~

Planned edition cadence:

  â€¢ **2025:** Launch edition (baseline)
  â€¢ **2028:** First evolution edition
  â€¢ **2031:** Second evolution edition
  â€¢ Continue every 3 years...

Each edition has:
  â€¢ 6-month beta period for community testing
  â€¢ Automated migration tools ready at launch
  â€¢ LTS support for at least 2 prior editions (6 years minimum)

Support Policy
~~~~~~~~~~~~~~

  â€¢ **Current edition:** Full support, all new features
  â€¢ **Previous edition:** Security fixes, critical bugs
  â€¢ **Two editions back:** Security fixes only
  â€¢ **Older editions:** Best-effort compatibility (compiler still accepts)

Example timeline for edition 2028:

    2028-01: Edition 2028 stable launch
    2031-01: Edition 2031 launch (2028 becomes "previous")
    2034-01: Edition 2034 launch (2028 becomes "two back")
    2037-01: Edition 2037 launch (2028 moves to best-effort)

Even after active support ends, the compiler continues to accept old editions.

Why Editions Matter
~~~~~~~~~~~~~~~~~~~

The edition system addresses the "stability vs evolution" dilemma:

  â€¢ **For established projects:** Guaranteed stability, no forced churn
  â€¢ **For new projects:** Access to latest improvements
  â€¢ **For the ecosystem:** Gradual, coordinated evolution
  â€¢ **For developers:** Confidence to invest in Pyrite

This is inspired by Rust's edition system, which successfully enabled language 
evolution (async/await, new keywords) without breaking millions of lines of 
existing code.

Trust Signal
~~~~~~~~~~~~

The edition system is a promise: "Your Pyrite code will compile in 10 years."

This commitment differentiates Pyrite from languages that break compatibility 
frequently (Python 2â†’3) or stagnate to avoid breaking changes. Pyrite evolves 
without breaking.

8.17 Supply-Chain Security and Trust
--------------------------------------------------------------------------------

For production systems and security-critical applications, supply-chain security 
is non-negotiable. Pyrite makes dependency trust and verification first-class 
features, not afterthoughts. This addresses the growing industry concern about 
software supply-chain attacks and dependency vulnerabilities.

Design Philosophy
~~~~~~~~~~~~~~~~~

Pyrite's approach to supply-chain security:
  â€¢ **Explicit verification:** Developers actively audit dependencies
  â€¢ **Reproducible builds:** Lockfiles and checksums prevent tampering
  â€¢ **Package signing:** Cryptographic verification of package authors
  â€¢ **Vulnerability scanning:** Automated detection of known CVEs
  â€¢ **Review manifests:** Organizations track trusted versions
  â€¢ **Minimal dependencies:** Batteries-included stdlib reduces attack surface

This makes Pyrite suitable for industries with strict security requirements 
(aerospace, medical devices, financial services, government).

quarry audit - Vulnerability Scanning
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Automated scanning for known security vulnerabilities in dependencies:

    quarry audit                           # Scan all dependencies
    quarry audit --json                    # Machine-readable output
    quarry audit --fix                     # Update to patched versions

Example output:

    $ quarry audit
    
    Security Audit Report
    =====================
    
    Scanning 47 dependencies...
    
    ğŸ”´ CRITICAL (2 vulnerabilities)
    
    1. CVE-2025-1234: Buffer overflow in json-parser 1.2.3
       Package: json-parser
       Installed: 1.2.3
       Fixed in: 1.2.4, 1.3.0
       Severity: CRITICAL (CVSS 9.8)
       
       Vulnerability:
         â€¢ Type: Heap buffer overflow
         â€¢ Component: JSON string parser
         â€¢ Exploitable: Remote code execution
         â€¢ Affected: parse_string() function
       
       Impact on your code:
         â€¢ Used in: src/api.py:156 (parse_json_request)
         â€¢ Exposure: User-supplied JSON input
         â€¢ Risk: High (external input, network-facing)
       
       Fix:
         Update to patched version:
           quarry update json-parser --version=1.2.4
         
         Or remove dependency if not critical:
           quarry remove json-parser
    
    ğŸŸ¡ WARNING (3 vulnerabilities)
    
    2. CVE-2024-5678: Denial of service in http-client 2.1.0
       [Details...]
    
    Summary:
      â€¢ 5 vulnerabilities found (2 critical, 3 warning)
      â€¢ 2 packages need updates
      â€¢ Run 'quarry audit --fix' to automatically update
    
    Last audit: 3 days ago
    Run 'quarry audit' regularly or enable in CI

CI Integration:

    # Fail CI if critical vulnerabilities found
    quarry audit --fail-on=critical
    
    # Fail on any vulnerability
    quarry audit --fail-on=any
    
    # Check and update automatically
    quarry audit --fix --ci

Audit database:
  â€¢ Quarry maintains central vulnerability database (quarry.dev/advisories)
  â€¢ Updated continuously from multiple sources (CVE, NVD, security researchers)
  â€¢ Community-reported vulnerabilities via quarry report-vuln

Benefits:
  â€¢ Continuous monitoring of known vulnerabilities
  â€¢ Automated detection in CI (no manual tracking)
  â€¢ Immediate notification of critical issues
  â€¢ One-command remediation (quarry audit --fix)

quarry vet - Dependency Review and Trust
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For organizations with strict security requirements, quarry vet provides 
dependency review and approval workflows inspired by cargo-vet:

    quarry vet                             # Show unvetted dependencies
    quarry vet review json-parser          # Review specific package
    quarry vet certify json-parser 1.2.4   # Mark version as trusted
    quarry vet import-audits --from=org    # Import organization audits

How it works:

1. **Track trusted versions:** Maintain manifest of reviewed dependencies
2. **Block unvetted packages:** Fail build if dependency not reviewed
3. **Share trust:** Organizations publish review manifests
4. **Continuous verification:** CI enforces vet requirements

Example workflow for security-critical organization:

    $ quarry vet
    
    Dependency Review Status
    ========================
    
    Unvetted dependencies (4):
    
    ğŸ”´ json-parser 1.2.4
       â€¢ Added: 2 days ago
       â€¢ Used by: src/api.py
       â€¢ Risk: Parses external input (network-facing)
       â€¢ Lines of unsafe code: 234 (12% of crate)
       â€¢ Previous version vetted: 1.2.3
       
       Action required:
         1. Review changes: quarry vet diff json-parser 1.2.3 1.2.4
         2. Audit unsafe blocks: quarry vet show-unsafe json-parser
         3. Certify if safe: quarry vet certify json-parser 1.2.4
    
    ğŸŸ¡ http-client 3.0.1
       â€¢ Added: 1 week ago
       â€¢ Used by: src/fetch.py
       â€¢ Risk: Network operations
       â€¢ Community reviews: 47 organizations vetted this version
       
       Quick certify (trusted by community):
         quarry vet certify http-client 3.0.1 --trust-community

Review process:

    $ quarry vet review json-parser 1.2.4
    
    Reviewing: json-parser 1.2.4
    ============================
    
    Package information:
      â€¢ Authors: security-team@example.com (verified)
      â€¢ Downloads: 1.2M last month
      â€¢ Stars: 3,400
      â€¢ Open issues: 12 (0 security-related)
    
    Changes since 1.2.3 (last vetted):
      â€¢ 15 commits
      â€¢ +234 lines, -89 lines
      â€¢ 2 unsafe blocks modified
    
    [Show diff] [Show unsafe code] [Check CVEs]
    
    Audit questions:
      1. Does it handle untrusted input safely? [Y/n]
      2. Are unsafe blocks justified and correct? [Y/n]
      3. Are dependencies vetted? [Y/n]
      4. Is error handling robust? [Y/n]
    
    Certify this version? [y/N]

Certification levels:

    quarry vet certify pkg 1.0 --level=full
      # Full audit: All code reviewed, all unsafe blocks verified
    
    quarry vet certify pkg 1.0 --level=safe-to-deploy
      # Safe for production: No known vulnerabilities, trusted author
    
    quarry vet certify pkg 1.0 --level=safe-to-run
      # Safe for development: No immediate security concerns

Import organization audits:

    # Use your organization's pre-vetted packages
    quarry vet import-audits --from=https://security.mycompany.com/pyrite-audits
    
    # Trust Mozilla's security team audits
    quarry vet import-audits --from=mozilla
    
    # Trust community consensus (50+ organizations)
    quarry vet import-audits --from=community --min-reviewers=50

Configuration (Quarry.toml):

    [vet]
    required = true                        # Fail build if unvetted deps
    import-audits = ["mozilla", "myorg"]   # Trust these sources
    allow-community = true                 # Trust community consensus
    min-community-reviews = 50             # Minimum reviewers for auto-trust

Benefits:
  â€¢ **Reduces supply-chain risk:** Every dependency explicitly reviewed
  â€¢ **Scales across organization:** Share audits, don't duplicate work
  â€¢ **Continuous verification:** CI enforces vet requirements
  â€¢ **Community trust:** Leverage collective security review efforts
  â€¢ **Audit trail:** Know who reviewed what and when

Use cases:
  â€¢ Aerospace: DO-178C requires dependency verification
  â€¢ Medical: IEC 62304 mandates security review
  â€¢ Finance: SOC 2 compliance requires supply-chain controls
  â€¢ Government: Executive Order 14028 mandates SBOM and verification

quarry sign - Package Signing
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Cryptographic signing of packages ensures authenticity and prevents tampering:

    # As package author
    quarry sign                            # Sign package with your key
    quarry publish --signed                # Publish with signature
    
    # As package consumer
    quarry install pkg --verify-sig        # Require valid signature
    quarry config set verify-signatures always  # Enforce for all installs

Key management:

    quarry keygen                          # Generate signing keypair
    quarry key publish                     # Publish public key to registry
    quarry key import author@example.com   # Import author's public key

Package signature verification:

    $ quarry verify json-parser
    
    Signature Verification: json-parser 1.2.4
    =========================================
    
    âœ“ Package signed by: security-team@example.com
    âœ“ Signature valid (RSA-4096)
    âœ“ Public key verified (published 2023-04-15)
    âœ“ Checksum matches: a8f39d...
    âœ“ No tampering detected
    
    Author reputation:
      â€¢ 47 packages published
      â€¢ 12M total downloads
      â€¢ 0 reported vulnerabilities
      â€¢ Verified email domain

Quarry.toml configuration:

    [security]
    require-signatures = true              # Only install signed packages
    trusted-authors = [
        "security-team@example.com",
        "mozilla-team@mozilla.org"
    ]
    verify-checksums = true                # Always verify SHA-256
    reject-unsigned = true                 # Fail on unsigned packages

Registry enforcement:
  â€¢ Quarry Registry (quarry.dev) encourages signing (badged packages)
  â€¢ Security-sensitive packages require signing for featured status
  â€¢ Signature verification integrated into quarry install by default

Reproducible Builds and SBOM
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Software Bill of Materials (SBOM) generation for supply-chain transparency:

    quarry sbom                            # Generate SBOM for project
    quarry sbom --format=spdx              # SPDX format
    quarry sbom --format=cyclonedx         # CycloneDX format

Example SBOM output:

    {
      "bomFormat": "CycloneDX",
      "version": "1.4",
      "components": [
        {
          "name": "json-parser",
          "version": "1.2.4",
          "purl": "pkg:quarry/json-parser@1.2.4",
          "hashes": [{"alg": "SHA-256", "content": "a8f39d..."}],
          "licenses": ["MIT"],
          "supplier": {"name": "security-team@example.com"},
          "signature": "----------BEGIN SIGNATURE----------..."
        },
        // ... all dependencies ...
      ],
      "dependencies": [
        {"ref": "json-parser", "dependsOn": ["string-utils"]}
      ]
    }

Reproducible build verification:

    quarry build --reproducible            # Enable reproducible build mode
    quarry verify-build --sbom=project.sbom  # Verify build matches SBOM

Benefits:
  â€¢ Compliance: Meet regulatory requirements (executive orders, standards)
  â€¢ Transparency: Complete visibility into dependency tree
  â€¢ Verification: Confirm what's in the binary matches declared dependencies
  â€¢ Incident response: Quickly identify affected systems when CVE announced

Use cases:
  â€¢ Government contracts (SBOM required)
  â€¢ Healthcare (FDA guidance on software dependencies)
  â€¢ Finance (audit requirements)
  â€¢ Enterprise (security policy compliance)

Integration with CI/CD
~~~~~~~~~~~~~~~~~~~~~~

Complete supply-chain security pipeline:

    # .github/workflows/security.yml
    name: Security CI
    
    jobs:
      supply-chain:
        steps:
          - name: Audit dependencies
            run: quarry audit --fail-on=critical
          
          - name: Verify all dependencies are vetted
            run: quarry vet --enforce
          
          - name: Verify signatures
            run: quarry verify --all
          
          - name: Generate SBOM
            run: quarry sbom --format=spdx --output=sbom.json
          
          - name: Upload SBOM for compliance
            uses: actions/upload-artifact@v2
            with:
              name: software-bill-of-materials
              path: sbom.json

Dashboard integration:

    quarry security-dashboard
    
    Shows:
      â€¢ Dependency vulnerability count over time
      â€¢ Unvetted dependencies requiring review
      â€¢ Signature verification status
      â€¢ SBOM compliance status
      â€¢ Audit trail (who reviewed what)

Why Supply-Chain Security Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Supply-chain attacks are increasing (SolarWinds, Log4Shell, XZ Utils backdoor). 
Languages that make security an afterthought lose trust. Pyrite makes it 
first-class:

**Industry trends:**
  â€¢ Executive Order 14028 (2021): U.S. government mandates SBOM for software
  â€¢ EU Cyber Resilience Act: Requires vulnerability disclosure and updates
  â€¢ Open source supply-chain attacks: Up 650% from 2021-2024

**Pyrite's competitive advantage:**
  â€¢ Built-in tooling (not third-party bolted on)
  â€¢ Zero-friction security (quarry audit is one command)
  â€¢ Scalable verification (import organization audits)
  â€¢ Compliance-ready (SBOM generation standard)

**Real-world impact:**
  â€¢ Rust: cargo-vet adoption growing in security-critical orgs
  â€¢ npm: Signature verification added after multiple attacks
  â€¢ Go: SBOM support added in response to executive order
  â€¢ Pyrite: Ships with all of this on day one

For embedded-first strategy, supply-chain security is **table stakes**:
  â€¢ Aerospace: Supply-chain verification required for DO-178C
  â€¢ Medical: FDA guidance mandates software composition analysis
  â€¢ Automotive: ISO 26262 requires dependency security analysis
  â€¢ Industrial: IEC 62443 mandates secure development practices

Without supply-chain security: "Just another language"
With supply-chain security: "Enterprise-ready from day one"

This is a **love multiplier** - it costs implementation time, not language 
complexity, but makes Pyrite feel "serious" and "production-ready" to 
organizations evaluating systems languages for critical infrastructure.

Implementation Timeline
~~~~~~~~~~~~~~~~~~~~~~~

Stable Release:
  â€¢ quarry audit - Vulnerability database and scanning
  â€¢ quarry sign/verify - Package signing and verification
  â€¢ Basic SBOM generation
  â€¢ quarry vet - Full review workflow with organization audits
  â€¢ Advanced SBOM features (dependency graphs, license compliance)
  â€¢ Integration with enterprise security tools

Cost: Implementation time only (no language complexity)
Impact: Trust and adoption multiplier for security-critical domains
ROI: High (required for aerospace/medical/government adoption)

8.18 Binary Size Profiling (Beta Release)
--------------------------------------------------------------------------------

For embedded systems where flash memory is constrained (32KB-512KB typical), 
binary size transparency is as critical as performance profiling. The quarry bloat 
command provides detailed analysis of what's consuming binary space, enabling 
systematic size optimization.

Command Usage
~~~~~~~~~~~~~

    quarry bloat                     # Analyze binary size
    quarry bloat --sections          # Per-section breakdown
    quarry bloat --functions         # Per-function breakdown
    quarry bloat --compare=v1.0      # Track size over time
    quarry bloat --crates            # Per-dependency breakdown

Example Output
~~~~~~~~~~~~~~

    $ quarry bloat
    
    Binary Size Analysis
    ====================
    
    Target: ARM Cortex-M4 (256 KB flash budget)
    Binary: target/thumbv7em-none-eabi/release/firmware.elf
    
    Total: 47,234 bytes (46.1 KB)
    Available: 262,144 bytes (256 KB)
    Used: 18% of flash budget âœ“
    
    Largest Contributors:
    
    Section          Size      Percent
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    .text (code)     38,456    81.4%
    .rodata (data)   6,234     13.2%
    .data            1,544     3.3%
    .bss             1,000     2.1%
    
    Top 10 Functions by Size:
    
    Function                          Size      Percent   Crate
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. std::fmt::format_args          4,234     9.0%      std
    2. core::panic::panic_fmt         3,456     7.3%      core
    3. sensor::read_and_process       2,890     6.1%      app
    4. json::parse                    2,456     5.2%      json-parser
    5. List[u8]::grow                 1,234     2.6%      std
    6. uart::write_formatted          1,123     2.4%      hal
    7. String::fmt                    987       2.1%      std
    8. f32::to_string                 856       1.8%      core
    9. network::handle_packet         734       1.6%      app
    10. crypto::verify_signature      689       1.5%      crypto-lib
    
    Optimization Suggestions:
    
    ğŸ”´ HIGH IMPACT (save 14 KB):
    
      1. Replace std::fmt with core::fmt_minimal
         Current: 4,234 bytes (full formatting)
         Minimal: 856 bytes (basic formatting only)
         Savings: 3,378 bytes (7.1%)
         
         Change: Use --features=minimal-fmt
         Trade-off: Less flexible format strings
      
      2. Use --panic=abort instead of unwind
         Current: Panic handler + unwind = 3,456 bytes
         Abort: 234 bytes (just abort)
         Savings: 3,222 bytes (6.8%)
         
         Change: panic = "abort" in Quarry.toml
         Trade-off: No panic message on device (use debugger)
    
    ğŸŸ¡ MEDIUM IMPACT (save 4 KB):
    
      3. Remove unused generic instantiations
         List[u8], List[u16], List[u32] all present
         Code uses only List[u8]
         Savings: 2,468 bytes (5.2%)
         
         Run: quarry build --gc-sections (removes unused)

Comparison Mode
~~~~~~~~~~~~~~~

Track binary size over development:

    $ quarry bloat --compare=baseline.json
    
    Binary Size Comparison
    ======================
    
    Baseline: 42,156 bytes (v1.0.0)
    Current:  47,234 bytes (main branch)
    Change:   +5,078 bytes (+12.0%) âš ï¸
    
    New code added:
      â€¢ sensor::read_and_process: +2,890 bytes
      â€¢ json::parse dependency: +2,456 bytes
      â€¢ Formatting changes: +856 bytes
    
    Removed code:
      â€¢ Old sensor code: -1,124 bytes
    
    Regressions (unintended size increases):
      â€¢ List[u8]::grow: 1,234 â†’ 1,456 bytes (+222)
        Reason: New bounds checking logic added
        Consider: --no-bounds-check for release

Section Analysis
~~~~~~~~~~~~~~~~

Detailed per-section breakdown:

    $ quarry bloat --sections
    
    .text (Code) - 38,456 bytes
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    By module:
      app code:        12,345 bytes (32.1%)
      std library:     15,234 bytes (39.6%)
      dependencies:    8,456 bytes (22.0%)
      startup code:    2,421 bytes (6.3%)
    
    .rodata (Read-Only Data) - 6,234 bytes
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    String literals:  4,567 bytes (73.3%)
      â€¢ Error messages: 2,345 bytes
      â€¢ Log messages: 1,234 bytes
      â€¢ Config strings: 988 bytes
    
    Constants:        1,234 bytes (19.8%)
    Lookup tables:    433 bytes (6.9%)
    
    Suggestions:
      â€¢ Use --strip-strings to remove debug strings
      â€¢ Move config to external flash if available

Dependency Analysis
~~~~~~~~~~~~~~~~~~~

Show which dependencies contribute to binary size:

    $ quarry bloat --crates
    
    Size by Dependency
    ==================
    
    Crate               Size      Percent   Unused
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    std                 15,234    32.2%     2,345
    json-parser         8,456     17.9%     0
    crypto-lib          3,456     7.3%      567
    hal (hardware)      2,890     6.1%      0
    app (your code)     12,345    26.1%     0
    Other               4,853     10.3%     1,234
    
    Unused code: 4,146 bytes (8.8%)
      â†’ Run with --gc-sections to remove

CI Integration
~~~~~~~~~~~~~~

Enforce size budgets in continuous integration:

    # Quarry.toml
    [build]
    max-binary-size = "64KB"        # Fail if exceeded
    warn-binary-size = "60KB"       # Warn approaching limit
    
    # CI runs:
    $ quarry bloat --check
    
    âœ“ Binary size: 46.1 KB (under 64 KB limit)
    âš ï¸  Warning: 76% of limit (approaching 60 KB warning threshold)

Size Optimization Modes
~~~~~~~~~~~~~~~~~~~~~~~

Embedded-specific optimization flags:

    quarry build --optimize=size     # Aggressive size optimization
    quarry build --strip-all         # Remove all debug info, symbols
    quarry build --minimal-panic     # Smallest panic handler
    quarry build --no-strings        # Remove all string literals

Example optimization progression:

    # Default release
    $ quarry build --release
    Binary: 124 KB
    
    # Size-optimized
    $ quarry build --release --optimize=size
    Binary: 87 KB (30% reduction)
    
    # Minimal embedded
    $ quarry build --release --optimize=size --strip-all --minimal-panic
    Binary: 52 KB (58% reduction)

Integration with Cost Analysis
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Binary size correlates with quarry cost static analysis:

    $ quarry bloat --explain json::parse
    
    Function: json::parse
    =====================
    Size: 2,456 bytes
    
    Breakdown:
      â€¢ String parsing: 1,234 bytes (50%)
      â€¢ Number parsing: 567 bytes (23%)
      â€¢ Error handling: 432 bytes (18%)
      â€¢ Whitespace handling: 223 bytes (9%)
    
    Why this is large:
      â€¢ Generic over multiple integer types (4 instantiations)
      â€¢ Comprehensive error messages (345 bytes strings)
      â€¢ Bounds checking for all array accesses
    
    Alternatives:
      â€¢ json::parse_minimal - 856 bytes (no error messages)
      â€¢ json::parse_streaming - 1,123 bytes (lower memory, larger code)

Why Binary Size Profiling Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This is **essential for embedded-first strategy credibility:**

**Embedded constraints:**
  â€¢ STM32F103: 64 KB flash (common microcontroller)
  â€¢ Arduino Uno: 32 KB flash
  â€¢ ESP8266: 4 MB flash (large, but code + data + OTA = tight)
  â€¢ Every byte counts when targeting resource-constrained devices

**Competitive requirement:**
  â€¢ C/C++: Manual tracking, no tooling
  â€¢ Rust: cargo bloat (excellent, must match this)
  â€¢ Zig: Excellent size transparency
  â€¢ Pyrite: Must match or exceed Rust's bloat tool

**Trust factor:**
  â€¢ Embedded developers evaluate binary size immediately
  â€¢ "How big is 'Hello World'?" is first question
  â€¢ Visible bloat = "not serious about embedded"
  â€¢ Transparent profiling = "understands our constraints"

**Real-world validation:**
  â€¢ Rust's cargo bloat widely praised in embedded community
  â€¢ Binary size is top 3 concern for embedded (after correctness, performance)
  â€¢ Transparent tooling = confidence to adopt

Without quarry bloat, Pyrite's embedded-first positioning is incomplete. With it, 
Pyrite demonstrates: "We understand embedded constraints at the tooling level, 
not just language level."

Implementation: Beta Release (after core compilation is stable)
Priority: Critical for embedded-first strategy
Complexity: Low (parse ELF/PE/Mach-O symbols, sum sizes)
Impact: High (required for embedded credibility)

8.19 Deterministic and Reproducible Builds (Beta Release)
--------------------------------------------------------------------------------

To complete Pyrite's supply-chain security story and enable verifiable builds, 
Quarry provides deterministic compilation where identical source and 
configuration produce bit-for-bit identical binaries across all machines and 
environments.

Command Usage
~~~~~~~~~~~~~

    quarry build --deterministic     # Enable deterministic mode
    quarry build --reproducible      # Alias for --deterministic
    quarry verify-build              # Verify binary matches manifest
    quarry build-hash                # Generate content-addressable hash

Deterministic Mode
~~~~~~~~~~~~~~~~~~

When enabled, the compiler ensures reproducibility:

    $ quarry build --deterministic
    
    Building in deterministic mode...
    âœ“ Source hash: a8f39d4e...
    âœ“ Quarry.lock hash: b3c82f1a...
    âœ“ Compiler version: 1.0.0
    âœ“ Target: x86_64-linux
    
    Deterministic constraints enforced:
      â€¢ Fixed timestamps (SOURCE_DATE_EPOCH=1640000000)
      â€¢ Sorted symbol tables
      â€¢ Deterministic random seeds for layout randomization
      â€¢ Stable iteration order for codegen
    
    Binary: target/release/myapp
    Build hash: 7d5e9c8b3a4f2d1e... (SHA-256)
    
    Verification:
      quarry verify-build --hash=7d5e9c8b3a4f2d1e...

Configuration
~~~~~~~~~~~~~

Enable determinism by default:

    # Quarry.toml
    [build]
    deterministic = true             # All builds reproducible
    source-date-epoch = 1640000000   # Fixed timestamp
    
    [profile.release]
    deterministic = true             # Release builds always reproducible

Verification Workflow
~~~~~~~~~~~~~~~~~~~~~

Verify that a binary matches declared sources:

    $ quarry verify-build myapp --manifest=BuildManifest.toml
    
    Verifying: myapp
    ================
    
    Checking:
      âœ“ Source files match manifest (SHA-256 hashes)
      âœ“ Dependencies match Quarry.lock
      âœ“ Compiler version: 1.0.0 (expected: 1.0.0)
      âœ“ Build flags: --release --deterministic
      âœ“ Target: x86_64-linux
    
    Rebuilding to verify...
    âœ“ Rebuild complete
    âœ“ Binary hash matches: 7d5e9c8b3a4f2d1e...
    
    VERIFIED: Binary is reproducible from declared sources

Build Manifest Format
~~~~~~~~~~~~~~~~~~~~~

Generated for every deterministic build:

    # BuildManifest.toml (committed alongside binary)
    [build]
    hash = "7d5e9c8b3a4f2d1e..."
    timestamp = "2025-12-18T10:30:00Z"
    compiler = "1.0.0"
    target = "x86_64-linux"
    flags = ["--release", "--deterministic"]
    
    [sources]
    "src/main.pyrite" = { hash = "a8f39d4e...", size = 1234 }
    "src/lib.pyrite" = { hash = "b3c82f1a...", size = 5678 }
    
    [dependencies]
    "json-parser" = { version = "1.2.4", hash = "c4d93e2b..." }
    "http-client" = { version = "3.0.1", hash = "d5e04f3c..." }

Integration with Supply-Chain Security
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Reproducible builds complete the supply-chain story:

    # Verify everything about a binary
    $ quarry verify-supply-chain myapp
    
    Supply-Chain Verification
    ==========================
    
    âœ“ Binary reproducible from sources
    âœ“ All dependencies signed and verified
    âœ“ No known CVEs in dependency tree
    âœ“ All dependencies vetted by organization
    âœ“ SBOM generated and matches binary
    
    Trust level: âœ“âœ“âœ“âœ“âœ“ (5/5) - Fully verified

CI Enforcement
~~~~~~~~~~~~~~

Ensure builds remain reproducible:

    # .github/workflows/ci.yml
    - name: Verify reproducible build
      run: |
        quarry build --deterministic
        quarry verify-build --strict
        # Fails if build is non-deterministic

Content-Addressable Builds
~~~~~~~~~~~~~~~~~~~~~~~~~~~

For maximum security, store binaries by content hash:

    $ quarry build-hash
    
    Content Hash: 7d5e9c8b3a4f2d1e0c9f8a7b6d5e4f3a2b1c0d9e8f7
    
    Storage path:
      ~/.cache/quarry/builds/7d/5e/9c/7d5e9c8b.../myapp
    
    Reproduce:
      quarry build-from-hash 7d5e9c8b...

Why Deterministic Builds Matter
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This is **essential for supply-chain security** (incomplete without it):

**Security requirements:**
  â€¢ Can't verify "this binary came from this source" without reproducibility
  â€¢ Supply-chain attacks undetectable without build verification
  â€¢ Debian, Arch Linux, F-Droid all require reproducible builds
  â€¢ Government/military: Build verification mandatory

**Competitive landscape:**
  â€¢ Rust: Reproducible by default (proven)
  â€¢ Go: Reproducible with flags
  â€¢ Zig: Strong emphasis on reproducibility
  â€¢ Pyrite: **Must match this** for credibility

**Real-world impact:**
  â€¢ SolarWinds attack: Non-reproducible builds hid backdoor
  â€¢ XZ Utils backdoor: Reproducible builds would have caught it earlier
  â€¢ Industry trend: Reproducibility becoming standard requirement

**Trust multiplier:**
  â€¢ "You can verify the binary you run" â†’ confidence
  â€¢ "Build hash is proof" â†’ auditable
  â€¢ "No hidden modifications" â†’ trustworthy

**Integration with existing features:**
  â€¢ quarry sign signs the BuildManifest + binary hash
  â€¢ quarry vet verifies dependencies' build hashes
  â€¢ quarry audit checks CVEs based on verified source versions
  â€¢ quarry sbom includes build hash for traceability

Without deterministic builds, supply-chain security (Section 8.17) is incomplete. 
With it, Pyrite offers the complete package: audit + vet + sign + verify + 
reproducible. This is **table-stakes for aerospace, medical, and government 
contracts.**

Implementation: Beta Release (high priority for supply-chain security)
Complexity: Moderate (requires compiler determinism work)
Impact: Critical (required for security certification and trust)

8.20 Energy Profiling (Stable Release)
--------------------------------------------------------------------------------

To address sustainability concerns and optimize for battery-powered devices, 
Pyrite provides built-in energy profiling that makes power consumption visible 
and optimizable. This is a **unique differentiator** - no other systems language 
has first-class energy awareness.

Command Usage
~~~~~~~~~~~~~

    quarry energy                    # Profile energy consumption
    quarry energy --duration=60s     # Profile for 60 seconds
    quarry energy --compare=baseline # Detect energy regressions
    quarry energy --json             # Machine-readable output

Example Output
~~~~~~~~~~~~~~

    $ quarry energy
    
    Energy Profile (30s run, Intel i9-12900K)
    ==========================================
    
    Total energy: 45.2 joules
    Average power: 1.51 watts
    Peak power: 8.3 watts
    
    Energy Hot Spots (by component):
    
    Component            Energy    Power    Percent
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    CPU cores            28.4 J    0.95 W   62.8%
    DRAM                 9.2 J     0.31 W   20.4%
    CPU package          5.6 J     0.19 W   12.4%
    GPU (idle)           2.0 J     0.07 W   4.4%
    
    Top Energy-Consuming Functions:
    
    Function                Energy    CPU Time   Efficiency
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. matrix_multiply      18.2 J    5.2s       3.5 J/s
       â€¢ AVX-512 active (high power draw)
       â€¢ 12 cores utilized
       â€¢ Suggestion: Lower SIMD width for battery mode
    
    2. network_poll         12.4 J    15.8s      0.78 J/s
       â€¢ Polling every 10ms (prevents CPU sleep)
       â€¢ 1,580 wake-ups
       â€¢ Suggestion: Adaptive polling (100ms when idle)
       â€¢ Energy savings: 60%
    
    3. json_parse           8.6 J     3.1s       2.8 J/s
       â€¢ Memory-intensive (high DRAM power)
       â€¢ 4,567 allocations
       â€¢ Suggestion: Pre-allocate buffers

Battery Mode Optimization
~~~~~~~~~~~~~~~~~~~~~~~~~

Build with energy-aware optimizations:

    quarry build --optimize=battery
    
    # Or in Quarry.toml:
    [profile.battery]
    opt-level = 2                    # Balance speed and power
    simd-width = 4                   # Use SSE2, not AVX-512
    adaptive-polling = true          # Longer sleep periods
    cpu-frequency = "powersave"      # Hint to OS scheduler

Energy Budget Enforcement
~~~~~~~~~~~~~~~~~~~~~~~~~~

For battery-powered devices, enforce energy constraints:

    @energy_budget(joules=0.5, duration_s=1.0)
    fn process_sensor_reading(data: &[u8]) -> Result[Reading, Error]:
        # Compiler warns if energy budget exceeded
        # Based on hardware model + instruction costs
        ...

Example enforcement:

    warning[P1501]: energy budget may be exceeded
      ----> src/sensor.py:45:5
       |
    43 | @energy_budget(joules=0.5, duration_s=1.0)
    44 | fn process_sensor_reading(data: &[u8]) -> Result[Reading, Error]:
    45 |     let result = expensive_fft(data)
       |                  ^^^^^^^^^^^^^^^^^^^ estimated 0.8 J (exceeds 0.5 J)
       |
       = note: FFT on 1024 samples estimated at 0.8 joules
       = help: Consider:
               1. Reduce sample size: fft(&data[0..512])
               2. Use lower-power algorithm: fast_approximation()
               3. Increase budget if justified

Platform Support
~~~~~~~~~~~~~~~~

Energy profiling requires platform-specific APIs:

  â€¢ **Linux:** RAPL (Running Average Power Limit) via perf
  â€¢ **macOS:** powermetrics (requires sudo)
  â€¢ **Windows:** ETW (Event Tracing for Windows) power events
  â€¢ **Embedded:** Hardware-specific power monitors (STM32 power profiler, etc.)
  â€¢ **Android/iOS:** Platform battery APIs

Fallback for unsupported platforms:
  â€¢ Estimate based on instruction costs + hardware models
  â€¢ Warn: "Energy profiling unavailable, showing estimates"

Battery-Life Estimation
~~~~~~~~~~~~~~~~~~~~~~~

For mobile/embedded applications:

    $ quarry energy --battery=2500mAh --voltage=3.7V
    
    Battery Life Estimate
    =====================
    
    Battery capacity: 2500 mAh Ã— 3.7 V = 9.25 Wh = 33,300 J
    Average power: 1.51 W
    
    Estimated battery life:
      â€¢ Continuous operation: 6.1 hours
      â€¢ With sleep mode (90% idle): 48 hours
    
    Breakdown:
      â€¢ Active processing: 1.51 W Ã— 10% = 0.151 W
      â€¢ Sleep mode: 0.05 W Ã— 90% = 0.045 W
      â€¢ Average: 0.196 W
      â€¢ Battery life: 33,300 J / 0.196 W / 3600 = 47.2 hours

Why Energy Profiling Is a Differentiator
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**No systems language has built-in energy profiling:**
  â€¢ C/C++: External tools only (Intel VTune, etc.)
  â€¢ Rust: No energy tooling
  â€¢ Zig: No energy tooling
  â€¢ Go: No energy tooling
  â€¢ Mojo: No energy tooling
  â€¢ **Pyrite: First-class feature**

**Growing importance:**
  â€¢ **Sustainability:** Green software movement (reduce data center energy)
  â€¢ **Mobile:** Battery life is primary UX constraint
  â€¢ **Embedded IoT:** Coin-cell batteries (years of operation required)
  â€¢ **Cloud costs:** Energy = money (AWS/Azure charge for power)
  â€¢ **Regulatory:** EU energy efficiency requirements for devices

**Marketing message:**
  â€¢ "The energy-aware systems language"
  â€¢ "Optimize for battery life, not just speed"
  â€¢ "Sustainability by design"

**Practical value:**
  â€¢ IoT devices: Optimize for coin-cell battery (10+ years target)
  â€¢ Mobile apps: "Our app uses 40% less battery" (competitive advantage)
  â€¢ Data centers: Reduce cooling costs (energy efficiency)
  â€¢ Laptops: Longer battery life = better UX

**Integration with existing tools:**
  â€¢ quarry cost shows allocations â†’ correlate with DRAM power
  â€¢ quarry perf shows CPU usage â†’ correlate with CPU power
  â€¢ quarry energy synthesizes: "This allocation costs 0.2 mJ"

This positions Pyrite as forward-thinking: not just fast and safe, but 
**responsible**. Sustainability-conscious developers (growing demographic) will 
appreciate that Pyrite considers the environmental impact of software.

Implementation: Stable Release (requires platform-specific power APIs)
Priority: Medium (unique differentiator, growing importance)
Complexity: Moderate (platform-specific integrations)
Impact: High (unique positioning, sustainability appeal)

8.21 Dead Code Analysis and Elimination (Beta Release)
--------------------------------------------------------------------------------

To optimize binary size and maintainability, Quarry provides comprehensive dead 
code detection and removal tooling.

Command Usage
~~~~~~~~~~~~~

    quarry deadcode                  # Find unused code
    quarry deadcode --remove         # Remove dead code automatically
    quarry build --gc-sections       # Link-time dead code elimination

Example Output
~~~~~~~~~~~~~~

    $ quarry deadcode
    
    Dead Code Analysis
    ==================
    
    Found 23 unused items (3,456 bytes in binary)
    
    Unused functions (18):
      â€¢ src/utils.py:45 - old_algorithm() [234 bytes]
        Last used: Never
        Suggestion: Remove or mark @deprecated
      
      â€¢ src/parser.py:123 - parse_legacy_format() [567 bytes]
        Last used: Removed in v1.2.0
        Suggestion: Remove (format no longer supported)
    
    Unused types (3):
      â€¢ src/types.py:89 - struct LegacyConfig [145 bytes]
        Never instantiated
        Suggestion: Remove or document why kept
    
    Unused imports (2):
      â€¢ src/main.py:5 - import old_crypto
        Module imported but never used
    
    Generic instantiations never called (5):
      â€¢ List[u16] instantiated but never used [1,234 bytes]
      â€¢ Map[i8, String] instantiated but never used [876 bytes]
    
    Total savings if removed: 3,456 bytes (7.3% of binary)
    
    Run 'quarry deadcode --remove' to apply

Automatic Removal
~~~~~~~~~~~~~~~~~

    $ quarry deadcode --remove --dry-run
    
    Would remove:
      â€¢ 18 unused functions
      â€¢ 3 unused types
      â€¢ 2 unused imports
      â€¢ 5 generic instantiations
    
    Apply? [y/N]

Link-Time Optimization
~~~~~~~~~~~~~~~~~~~~~~

    quarry build --gc-sections
    
    # Linker removes unreferenced sections
    # Effective for:
    #   â€¢ Generic instantiations never called
    #   â€¢ Library functions never used
    #   â€¢ Debug code in release builds

Integration with CI
~~~~~~~~~~~~~~~~~~~

    # Fail CI if dead code exceeds threshold
    quarry deadcode --threshold=1KB --fail
    
    error: Dead code exceeds 1KB threshold
      Current: 3.456 KB unused
      Threshold: 1 KB
    
    CI FAILURE: Remove dead code before merging

Why Dead Code Analysis Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Binary size optimization:**
  â€¢ Embedded: Every byte of flash matters
  â€¢ Distribution: Smaller binaries download faster
  â€¢ Security: Less code = smaller attack surface

**Code quality:**
  â€¢ Dead code is technical debt
  â€¢ Confuses new contributors
  â€¢ May hide bugs (code not tested because never called)

**Maintenance:**
  â€¢ Clear signal: "This code isn't used, safe to remove"
  â€¢ Prevents accumulation of cruft
  â€¢ Keeps codebase lean

Implementation: Beta Release (after core compilation is stable)
Priority: Medium-High (valuable for embedded + maintainability)
Complexity: Low (static analysis + symbol table inspection)
Impact: Medium-High (binary size + code quality)

8.22 Dependency License Compliance (Stable Release)
--------------------------------------------------------------------------------

For organizations with legal requirements, Quarry provides license compatibility 
checking and reporting to ensure dependency licenses are compatible with project 
requirements.

Command Usage
~~~~~~~~~~~~~

    quarry license-check             # Verify license compatibility
    quarry license-report            # Generate license report
    quarry sbom --licenses           # Include in SBOM

License Configuration
~~~~~~~~~~~~~~~~~~~~~

    # Quarry.toml
    [package]
    license = "MIT"
    
    [licenses]
    allowed = ["MIT", "Apache-2.0", "BSD-3-Clause"]
    denied = ["GPL-3.0", "AGPL-3.0"]  # Copyleft incompatible with MIT
    warn = ["LGPL-2.1"]                # Requires review

Example Output
~~~~~~~~~~~~~~

    $ quarry license-check
    
    License Compatibility Report
    =============================
    
    Your project: MIT License
    
    Dependencies: 47 packages
    
    âœ“ Compatible: 44 packages
      â€¢ 32 packages: MIT
      â€¢ 8 packages: Apache-2.0
      â€¢ 4 packages: BSD-3-Clause
    
    âš ï¸  Requires Review: 2 packages
      â€¢ json-parser 1.2.4: LGPL-2.1
        Note: LGPL requires dynamic linking or source distribution
        Your usage: Static linking
        Risk: License violation
        
        Options:
          1. Switch to MIT-licensed alternative: json-fast 2.0
          2. Use dynamic linking (--crate-type=dylib)
          3. Provide source distribution (LGPL compliance)
      
      â€¢ crypto-lib 3.0: ISC
        Note: ISC is MIT-compatible but not in allowed list
        Action: Add "ISC" to allowed licenses if acceptable
    
    âœ— INCOMPATIBLE: 1 package
      â€¢ legacy-parser 0.8: GPL-3.0
        Conflict: GPL-3.0 is copyleft, incompatible with MIT
        Your project cannot use this dependency
        
        Fix:
          1. Remove dependency: quarry remove legacy-parser
          2. Find alternative with compatible license
          3. Relicense your project (if all contributors agree)
    
    CI FAILURE: Incompatible licenses detected

CI Enforcement
~~~~~~~~~~~~~~

    # .github/workflows/ci.yml
    - name: Check license compatibility
      run: quarry license-check --fail-on=incompatible

License Report Generation
~~~~~~~~~~~~~~~~~~~~~~~~~

    $ quarry license-report --format=markdown
    
    # Generated: LICENSES.md
    
    # Third-Party Licenses
    
    This project includes the following dependencies:
    
    ## MIT License (32 packages)
    - json-parser 1.2.4
    - http-client 3.0.1
    [... full license text ...]
    
    ## Apache-2.0 (8 packages)
    - crypto-lib 3.0
    [... full license text ...]

Integration with SBOM
~~~~~~~~~~~~~~~~~~~~~

    $ quarry sbom --licenses --format=spdx
    
    {
      "components": [
        {
          "name": "json-parser",
          "version": "1.2.4",
          "licenses": ["LGPL-2.1"],
          "license-text": "...",
          "license-url": "https://opensource.org/licenses/LGPL-2.1"
        }
      ]
    }

Why License Compliance Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Legal requirements:**
  â€¢ Enterprises: Legal departments require license audits
  â€¢ Open source: GPL contamination prevents commercial use
  â€¢ Distribution: App stores require license disclosure

**Competitive feature:**
  â€¢ Rust: cargo-license (third-party, not built-in)
  â€¢ Go: go-licenses (third-party)
  â€¢ Pyrite: First-class built-in feature

**Trust signal:**
  â€¢ Shows Pyrite understands enterprise needs
  â€¢ Reduces legal risk for adopters
  â€¢ Makes Pyrite "enterprise-ready"

Implementation: Stable Release (extends SBOM work)
Priority: Medium (enterprise adoption enabler)
Complexity: Low (parse license metadata, check compatibility)
Impact: Medium (removes adoption barrier for regulated industries)

8.23 Hot Reloading for Rapid Iteration (Stable Release)
--------------------------------------------------------------------------------

For long-running processes during development, Quarry provides hot reloading that 
updates code without restarting the application, dramatically accelerating the 
iteration cycle for certain workflows.

Command Usage
~~~~~~~~~~~~~

    quarry dev                       # Watch mode with hot reload
    quarry dev --preserve-state      # Reload code, keep data structures
    quarry dev --functions-only      # Only reload function bodies

How It Works
~~~~~~~~~~~~

    $ quarry dev
    
    Starting development server...
    Watching: src/**/*.pyrite
    
    âœ“ Initial build complete
    âœ“ Application running (PID 12345)
    âœ“ Hot reload enabled
    
    Press Ctrl+C to stop, Ctrl+R to force reload
    
    [10:30:15] File changed: src/renderer.pyrite
    [10:30:15] Recompiling renderer module...
    [10:30:16] âœ“ Hot reloaded in 847ms
    [10:30:16] Application state preserved

Example Use Cases
~~~~~~~~~~~~~~~~~

**Game development:**

    # Game running at 60 FPS
    # Developer changes enemy AI logic
    # Hot reload updates AI without restarting game
    # Player position, score, etc. all preserved

**Web development:**

    # Server running, handling requests
    # Developer fixes bug in route handler
    # Hot reload updates handler function
    # Active connections preserved, no downtime

**Data processing:**

    # Processing large dataset (30 minutes expected)
    # Developer spots bug in processing function
    # Hot reload fixes bug mid-run
    # Already-processed data not re-computed

Restrictions and Safety
~~~~~~~~~~~~~~~~~~~~~~~

Hot reloading only works for certain changes:

    âœ“ Function bodies (logic changes)
    âœ“ Method implementations
    âœ“ Constants and static data
    âœ“ Module-level functions
    
    âœ— Type definitions (struct fields, enum variants)
    âœ— Function signatures (parameters, return types)
    âœ— Unsafe blocks (requires full recompilation)
    âœ— Dependency changes (requires restart)

When incompatible change detected:

    [10:35:42] File changed: src/types.pyrite
    [10:35:42] âœ— Cannot hot reload (struct fields changed)
    [10:35:42] Restart required: quarry dev --restart

Safety Guarantees
~~~~~~~~~~~~~~~~~

Hot reloading maintains safety:
  â€¢ Ownership rules still enforced (can't hot-reload into invalid state)
  â€¢ Type changes rejected (would break memory layout assumptions)
  â€¢ Unsafe changes rejected (require audit)
  â€¢ Only safe, compatible changes allowed

Implementation Approach
~~~~~~~~~~~~~~~~~~~~~~~

    1. Monitor source files for changes
    2. Incremental recompilation of changed module
    3. Dynamic library loading (dlopen) for new code
    4. Atomic function pointer swap (single instruction)
    5. Old code GC'd when no longer referenced

State Preservation
~~~~~~~~~~~~~~~~~~

Developer controls what state persists:

    @hot_reload(preserve_state = true)
    static mut CACHE: Map[String, Data] = Map::new()
    
    fn process(key: &str) -> Data:
        # CACHE survives hot reload
        # Function body can be updated

Configuration
~~~~~~~~~~~~~

    # Quarry.toml
    [dev]
    hot-reload = true
    preserve-state = ["CACHE", "CONNECTIONS"]
    watch-paths = ["src/**/*.pyrite"]
    ignore-paths = ["src/generated/**"]

Why Hot Reloading Matters
~~~~~~~~~~~~~~~~~~~~~~~~~~

**Developer joy:**
  â€¢ Game dev: Tweak gameplay without losing session
  â€¢ Web dev: See changes instantly (no restart)
  â€¢ Data science: Iterate on algorithms mid-computation
  â€¢ Learning: Faster experimentation ("what if I change this?")

**Competitive parity:**
  â€¢ Rust: rust-analyzer supports limited hot reload
  â€¢ Erlang/Elixir: Hot code swapping is flagship feature
  â€¢ JavaScript: Hot Module Replacement (HMR) standard
  â€¢ Python: importlib.reload() for modules

**Productivity multiplier:**
  â€¢ Restart time: 5-30 seconds typical
  â€¢ Hot reload: <1 second
  â€¢ 100 iteration cycles: 8-50 minutes saved per session

**Limitations:**
  â€¢ Debug builds only (not for production)
  â€¢ Requires explicit design (not all code hot-reloadable)
  â€¢ Best effort (some changes still require restart)

Implementation: Stable Release (after incremental compilation is stable)
Priority: Medium (developer experience enhancement)
Complexity: High (dynamic loading, state management)
Impact: Medium-High (productivity boost for certain workflows)

8.24 Incremental Compilation (Beta Release)
--------------------------------------------------------------------------------

Fast rebuilds are essential for developer productivity. Quarry implements 
incremental compilation to cache unchanged modules and recompile only what's 
necessary.

Command Usage
~~~~~~~~~~~~~

    quarry build --incremental       # Enable incremental compilation (default)
    quarry build --no-incremental    # Force full rebuild
    quarry clean --incremental       # Clear incremental cache

How It Works
~~~~~~~~~~~~

    $ quarry build --incremental
    
    Checking incremental cache...
    âœ“ Cached: 234 modules (unchanged)
    âœ“ Recompiling: 3 modules (modified)
    âœ“ Relinking: target/debug/myapp
    
    Finished in 1.8s (full build: 28s, 15.5x faster)

Incremental Strategy
~~~~~~~~~~~~~~~~~~~~

Compiler tracks:
  â€¢ Source file hashes (detect changes)
  â€¢ Dependency graph (what depends on what)
  â€¢ Module interface fingerprints (detect API changes)
  â€¢ Cached compilation artifacts per module

Rebuild decision tree:
  â€¢ File unchanged â†’ use cached artifact
  â€¢ File changed, interface unchanged â†’ recompile, no downstream rebuilds
  â€¢ File changed, interface changed â†’ recompile + all dependents

Example:

    src/utils.pyrite:
      - Changed: Implementation only (private function)
      - Interface: Unchanged (public API same)
      - Action: Recompile utils.pyrite only
      - Dependents: No rebuild needed
    
    src/types.pyrite:
      - Changed: Added struct field
      - Interface: Changed (public API modified)
      - Action: Recompile types.pyrite + all dependents
      - Dependents: main.pyrite, parser.pyrite, renderer.pyrite (all rebuild)

Performance Characteristics
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Typical rebuild times:

    | Project Size      | Full Build | Incremental | Speedup |
    |-------------------|------------|-------------|---------|
    | Small (10K LOC)   | 3s         | 0.5s        | 6x      |
    | Medium (100K)     | 28s        | 1.8s        | 15x     |
    | Large (1M)        | 320s       | 12s         | 27x     |

Cache Management
~~~~~~~~~~~~~~~~

    quarry cache info                # Show cache statistics
    quarry cache clean               # Remove stale cache entries
    quarry cache purge               # Delete entire cache

Example cache info:

    Incremental Cache Statistics
    =============================
    
    Location: ~/.cache/quarry/incremental
    Size: 1.2 GB (234 projects cached)
    
    Current project:
      â€¢ Cached modules: 234
      â€¢ Cache size: 45 MB
      â€¢ Last full build: 2025-12-18 10:30:00
      â€¢ Incremental builds: 147 since last full build
      â€¢ Average incremental time: 1.2s

Why Incremental Compilation Is Essential
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Developer experience:**
  â€¢ Fast iteration = more experimentation
  â€¢ Slow rebuilds = frustration, context switching
  â€¢ 1-2s rebuilds feel instant, 30s rebuilds feel slow

**Competitive requirement:**
  â€¢ Rust: Incremental compilation standard (expected)
  â€¢ Go: Fast compilation by default
  â€¢ C++: ccache, distcc for incremental builds
  â€¢ **Without this, Pyrite feels slow even if compiler is fast**

**Learning impact:**
  â€¢ Beginners iterate more when feedback is instant
  â€¢ "Change â†’ test" loop should be <5s
  â€¢ Slow rebuilds discourage experimentation

**Real-world data:**
  â€¢ Google: 30% productivity increase with faster builds
  â€¢ Rust: Incremental compilation adoption correlated with satisfaction
  â€¢ Developer survey: "Fast builds" in top 5 language features

Implementation: Beta Release (essential for developer experience)
Priority: Critical (expected feature, high impact on satisfaction)
Complexity: Moderate (requires module dependency tracking)
Impact: High (productivity multiplier for all developers)

8.25 Community Transparency Dashboard (Stable Release)
--------------------------------------------------------------------------------

To make Pyrite's goal of widespread developer adoption measurable rather than purely 
aspirational, the ecosystem provides a public metrics dashboard at quarry.dev/metrics that 
displays real-time, verifiable data about language performance, safety, 
learning, and adoption.

Dashboard Contents
~~~~~~~~~~~~~~~~~~

**Performance Metrics (User-Submitted Benchmarks):**

    Pyrite vs Competitors (1,247 benchmarks)
    ========================================
    
    Average performance relative to C:
      â€¢ Pyrite: 98.3% of C speed
      â€¢ Rust: 97.1% of C speed
      â€¢ Zig: 99.1% of C speed
      â€¢ Go: 82.4% of C speed
    
    Compilation speed:
      â€¢ Pyrite: 1.2s average (100K LOC project)
      â€¢ Rust: 8.4s average
      â€¢ C++: 12.3s average
      â€¢ Go: 0.8s average
    
    Binary size (Hello World):
      â€¢ Pyrite: 312 KB
      â€¢ Rust: 387 KB
      â€¢ C (dynamic): 8 KB
      â€¢ C (static): 2.1 MB
      â€¢ Go: 2.0 MB

**Safety Metrics (CVE Tracking):**

    Memory Safety CVEs (2020-2025)
    ===============================
    
    Language    Total CVEs    Memory-Related    Percentage
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    C           1,247         892               71.5%
    C++         1,089         654               60.1%
    Rust        23            0                 0%
    Go          89            4                 4.5%
    Pyrite      0             0                 0%
    
    Data races:
      â€¢ C/C++: Not preventable by language
      â€¢ Rust: 0 (prevented by type system)
      â€¢ Go: 12 (race detector catches at runtime)
      â€¢ Pyrite: 0 (prevented by ownership system)

**Learning Metrics (quarry learn Data):**

    Learning Curve Analysis
    =======================
    
    Exercise completion rates:
      â€¢ Ownership exercises: 82% complete all 12
      â€¢ SIMD exercises: 67% complete
      â€¢ Concurrency: 74% complete
    
    Comparison with Rust:
      â€¢ Rust ownership exercises: 64% complete
      â€¢ Pyrite advantage: 28% higher completion
    
    Time to productivity:
      â€¢ Pyrite: 2.3 weeks average (first PR)
      â€¢ Rust: 4.1 weeks average
      â€¢ C++: 6.8 weeks average
    
    quarry fix usage:
      â€¢ 89% of beginners use quarry fix --interactive
      â€¢ Average fixes per developer: 147
      â€¢ Adoption: "Compiler taught me ownership" - 94%

**Ecosystem Health:**

    Quarry Registry Metrics
    =======================
    
    Total packages: 15,247
    Growth: +23% month-over-month
    
    Package categories:
      â€¢ Embedded/HAL: 3,456 packages
      â€¢ Web frameworks: 2,345 packages
      â€¢ CLI tools: 1,890 packages
      â€¢ Crypto/security: 1,234 packages
    
    Active maintainers: 2,340 (â†‘ 18% MoM)
    Security audits: 1,456 packages vetted
    
    Dependency health:
      â€¢ 94% of packages updated in last 6 months
      â€¢ Average dependencies: 4.2 (vs Rust: 8.7)
      â€¢ Batteries-included stdlib reduces dependency hell

**Compile-Time Safety:**

    Bugs Caught at Compile Time
    ============================
    
    (Data from user error reports)
    
    Error category               Frequency   C/C++ equivalent
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Use-after-move              34.2%       Use-after-free (segfault)
    Borrow conflicts            23.5%       Data races (UB)
    Type mismatches             18.7%       Type punning (UB)
    Unhandled errors            12.4%       Unchecked returns (bugs)
    Lifetime violations         11.2%       Dangling pointers (segfault)
    
    Estimated bugs prevented: 3,247 per 100K LOC
    (Compared to typical C/C++ project with same code structure)

**Adoption Metrics:**

    Production Deployments
    ======================
    
    Companies using Pyrite: 1,247
    Industries:
      â€¢ Embedded/IoT: 34%
      â€¢ Web services: 28%
      â€¢ Gaming: 15%
      â€¢ Finance: 12%
      â€¢ Other: 11%
    
    Lines of code in production: 47M
    Developer satisfaction: 8.7/10
    Would recommend: 89%

Public API
~~~~~~~~~~

Dashboard data accessible via API:

    # Query metrics programmatically
    curl https://quarry.dev/api/metrics/performance
    
    # Embed in documentation
    <script src="https://quarry.dev/widgets/metrics.js"></script>

Community Contribution
~~~~~~~~~~~~~~~~~~~~~~

Users can submit benchmark data:

    quarry bench --upload            # Upload benchmark to metrics
    quarry bench --compare=community # Compare with community average

Privacy and opt-in:
  â€¢ Anonymous by default (no personal data)
  â€¢ Opt-in for benchmark submission
  â€¢ Aggregated statistics only (no individual user data)

Why Transparency Dashboard Is Transformative
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Makes developer adoption measurable:**

  â€¢ Not subjective claim, but verifiable data
  â€¢ "98% of C speed" with proof, not promises
  â€¢ "82% complete ownership exercises" shows teachability
  â€¢ Real-world evidence beats marketing claims

**Competitive positioning:**
  â€¢ Direct comparison with C/Rust/Zig/Mojo
  â€¢ Show strengths objectively (compile speed, safety, learning curve)
  â€¢ Acknowledge trade-offs honestly (ecosystem size, maturity)

**Trust multiplier:**
  â€¢ "See the data yourself" builds confidence
  â€¢ Open data = transparent community
  â€¢ Track progress over time (metrics improve as language matures)

**Gamification:**
  â€¢ Package maintainers compete for "most-used" ranking
  â€¢ Contributors see impact ("my PR improved compile time 12%")
  â€¢ Community engagement through visible metrics

**Evidence-based advocacy:**
  â€¢ "Pyrite caught 3,247 bugs per 100K LOC" â†’ share with CTO
  â€¢ "15x faster compilation than Rust" â†’ share with team
  â€¢ "28% higher learning success rate" â†’ share with educators

**Example impact:**
  â€¢ Rust doesn't have public dashboard â†’ metrics scattered
  â€¢ Go has limited metrics â†’ not comprehensive
  â€¢ Pyrite dashboard â†’ one place for all evidence
  â€¢ Result: "Just look at quarry.dev/metrics" becomes standard response

This transforms subjective claims into objective evidence. The path to "most 
admired" becomes visible: watch metrics improve over time, celebrate milestones 
publicly, demonstrate progress to skeptics.

Implementation: Stable Release (after core language is stable)
Priority: High (trust multiplier, advocacy enabler)
Complexity: Moderate (web dashboard, data aggregation, privacy)
Impact: High (makes success measurable, enables evidence-based marketing)

8.26 Why Quarry Matters
--------------------------------------------------------------------------------

Developer Experience = Language Adoption
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Stack Overflow surveys correlate Rust's growth with Cargo's excellence. Quarry 
delivers similar experience:

  â€¢ Zero configuration for common cases
  â€¢ One obvious way to do things
  â€¢ Fast, reliable builds with caching
  â€¢ Reproducible across environments
  â€¢ Integrated testing, docs, formatting
  â€¢ Frictionless dependency management
  â€¢ Cross-compilation out of the box
  â€¢ Script mode for rapid prototyping
  â€¢ Edition system for long-term stability

Quarry transforms Pyrite from "interesting language" to "practical tool I want 
to use daily." Great tooling is the difference between languages that are 
admired in theory versus loved in practice.

---

**Part of**: [Pyrite Language Specification](../SSOT.md)

**Previous**: [Advanced Features (Traits, Generics, and More)](07-advanced-features.md)

**Next**: [Standard Library and Ecosystem](09-standard-library.md)
